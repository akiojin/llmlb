# llmlb アーキテクチャ設計方針

本ドキュメントはllmlbの設計方針を定義します。

## 1. llmlbの役割: ゲートウェイ

llmlbは**APIゲートウェイ**として機能します。

- エンドポイント（xLLM、Ollama、vLLM等）を**ブラックボックス**として扱う
- エンドポイントの内部状態（VRAM状況、モデルロード状態等）は把握しない
- 内部リソース管理はエンドポイント側の責任

### ゲートウェイの責務

| 責務 | 説明 |
|------|------|
| リクエストルーティング | クライアントからのリクエストを適切なエンドポイントに転送 |
| ヘルスチェック | エンドポイント単位の死活監視 |
| 負荷分散 | 複数エンドポイント間でのリクエスト分散 |
| 認証 | JWT認証（ダッシュボード）、APIキー認証（API） |
| モデル一覧 | エンドポイントへのポーリングで自動取得 |

### ゲートウェイが行わないこと

| 項目 | 理由 |
|------|------|
| VRAM状況の監視 | エンドポイント内部の詳細 |
| モデルロード状態の管理 | エンドポイント側の責任 |
| 推論キューの管理 | エンドポイント側の責任 |
| モデル単位のヘルスチェック | エンドポイント単位で十分 |

## 2. エンドポイント管理

### 登録情報

エンドポイント登録に必要な情報は最小限に抑えます：

| 項目 | 必須/任意 | 説明 |
|------|-----------|------|
| URL | 必須 | エンドポイントのベースURL |
| APIキー | 任意 | 認証が必要な場合のみ |
| 名前 | 任意 | 識別用の表示名 |

### モデル一覧の取得

エンドポイントが提供するモデル一覧は、エンドポイントの`/v1/models`APIを
ポーリングして自動取得します。llmlb側でモデル情報を手動管理しません。

### ヘルスチェック

- **対象**: エンドポイント単位
- **方式**: 定期的なHTTPリクエスト（`/health`または`/v1/models`）
- **判定**: レスポンスステータスコードによるオンライン/オフライン判定

モデル単位のヘルスチェックは行いません。モデルの可用性は
エンドポイントの`/v1/models`レスポンスに委ねます。

## 3. 負荷分散戦略: ラウンドロビン

llmlbは**ラウンドロビン**方式のみを採用します。

```text
リクエスト1 → エンドポイントA
リクエスト2 → エンドポイントB
リクエスト3 → エンドポイントC
リクエスト4 → エンドポイントA
...
```

### なぜラウンドロビンのみか

| 理由 | 説明 |
|------|------|
| OpenAI互換APIにメトリクスがない | 標準APIではエンドポイントの負荷状況を取得できない |
| ブラックボックス設計 | エンドポイントの内部状態に依存しない |
| シンプルで予測可能 | 動作が明確で、デバッグが容易 |
| 保守性が高い | 複雑なロジックを排除 |

メトリクスベースの負荷分散を実現するには、エンドポイント側が独自のメトリクスAPIを
提供する必要がありますが、これはOpenAI互換APIの範囲外であり、
ゲートウェイとしての設計方針に反します。

## 4. 設計原則

### シンプルさの優先

- 複雑な最適化より予測可能な動作を優先
- エンドポイントの詳細を抽象化し、疎結合を維持
- 各コンポーネントの責務を明確に分離

### ブラックボックスとしてのエンドポイント

```text
┌─────────────────────────────────────────────────┐
│                     llmlb                        │
│  ┌─────────────────────────────────────────┐    │
│  │ APIゲートウェイ                          │    │
│  │ - ルーティング                           │    │
│  │ - 認証                                   │    │
│  │ - ラウンドロビン負荷分散                 │    │
│  └─────────────────────────────────────────┘    │
└──────────────────────┬──────────────────────────┘
                       │
       ┌───────────────┼───────────────┐
       │               │               │
       ▼               ▼               ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│ エンドポイント│ │ エンドポイント│ │ エンドポイント│
│ (xLLM)       │ │ (vLLM)       │ │ (Ollama)     │
│              │ │              │ │              │
│ ブラック     │ │ ブラック     │ │ ブラック     │
│ ボックス     │ │ ボックス     │ │ ボックス     │
└──────────────┘ └──────────────┘ └──────────────┘
```

llmlbはエンドポイントの内部実装に依存せず、
OpenAI互換APIという共通インターフェースのみに依存します。
