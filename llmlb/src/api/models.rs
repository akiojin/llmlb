//! モデル管理API
//!
//! モデル一覧取得、登録、マニフェスト配信のエンドポイント
//!
//! このモジュールはEndpointRegistry/Endpoint型を使用しています。

use crate::common::error::{CommonError, LbError, RouterResult};
use crate::{
    db::models::ModelStorage,
    registry::models::{extract_repo_id, generate_model_id, ModelInfo},
    AppState,
};
use axum::{
    extract::{Path, State},
    http::StatusCode,
    response::IntoResponse,
    Json,
};
use once_cell::sync::Lazy;
use reqwest;
use serde::{Deserialize, Serialize};
use sqlx::SqlitePool;
use std::collections::HashMap;
use std::sync::RwLock;
use std::time::{Duration, Instant};

// NOTE: supported_models.json は廃止されました (2026-01-25)
// モデルアーキテクチャ認識はエンドポイント（xLLM）側の config.json ベースで行われます
// 詳細は SPEC-6cd7f960, SPEC-48678000 を参照

/// モデル名の妥当性を検証
///
/// 有効なモデル名の形式:
/// - `gpt-oss-20b`, `mistral-7b-instruct-v0.2` のようなファイル名ベース形式
/// - `openai/gpt-oss-20b` のような階層形式（HuggingFace互換）
///
/// SPEC-dcaeaec4 FR-2: 階層形式を許可
fn validate_model_name(model_name: &str) -> Result<(), LbError> {
    if model_name.is_empty() {
        return Err(LbError::InvalidModelName("Model name is empty".to_string()));
    }

    // 危険なパターンを禁止（パストラバーサル対策）
    if model_name.contains("..") || model_name.contains('\0') {
        return Err(LbError::InvalidModelName(format!(
            "Invalid model name (contains dangerous pattern): {}",
            model_name
        )));
    }

    // 先頭・末尾のスラッシュは禁止
    if model_name.starts_with('/') || model_name.ends_with('/') {
        return Err(LbError::InvalidModelName(format!(
            "Invalid model name (leading/trailing slash): {}",
            model_name
        )));
    }

    // 許可する文字: 小文字英数字、'-', '_', '.', '/'（ディレクトリセパレータ）
    if !model_name.chars().all(|c| {
        c.is_ascii_lowercase() || c.is_ascii_digit() || c == '-' || c == '_' || c == '.' || c == '/'
    }) {
        return Err(LbError::InvalidModelName(format!(
            "Invalid model name: {}",
            model_name
        )));
    }

    Ok(())
}

// NOTE: AvailableModelView, AvailableModelsResponse, Pagination, model_info_to_view() は
// /v0/models/available 廃止に伴い削除されました。

/// モデルのライフサイクル状態
#[derive(Debug, Clone, Serialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum LifecycleStatus {
    /// 登録リクエスト受付、キャッシュ待ち
    Pending,
    /// ダウンロード・変換中（キャッシュ処理中）
    Caching,
    /// ルーターにキャッシュ完了（ノードがアクセス可能）
    Registered,
    /// エラー発生
    Error,
}

/// モデルの状態（SPEC-6cd7f960）
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum ModelStatus {
    /// 対応モデル（未ダウンロード）
    Available,
    /// ダウンロード中
    Downloading,
    /// ダウンロード完了
    Downloaded,
}

/// HuggingFace動的情報
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct HfInfo {
    /// ダウンロード数
    #[serde(skip_serializing_if = "Option::is_none")]
    pub downloads: Option<u64>,
    /// いいね数
    #[serde(skip_serializing_if = "Option::is_none")]
    pub likes: Option<u64>,
}

// ===== HuggingFace Info Cache (SPEC-6cd7f960) =====

/// HF情報キャッシュエントリ
#[derive(Clone)]
struct HfInfoCacheEntry {
    fetched_at: Instant,
    info: HfInfo,
}

/// HF情報キャッシュ（TTL: 10分）
static HF_INFO_CACHE: Lazy<RwLock<HashMap<String, HfInfoCacheEntry>>> =
    Lazy::new(|| RwLock::new(HashMap::new()));

const HF_INFO_CACHE_TTL: Duration = Duration::from_secs(600); // 10分

/// HuggingFace APIからモデル情報を取得（キャッシュ付き）
async fn fetch_hf_info(http_client: &reqwest::Client, repo: &str) -> Option<HfInfo> {
    // キャッシュチェック（ロックポイズニング時はスキップ）
    if let Ok(cache) = HF_INFO_CACHE.read() {
        if let Some(entry) = cache.get(repo) {
            if entry.fetched_at.elapsed() < HF_INFO_CACHE_TTL {
                return Some(entry.info.clone());
            }
        }
    }

    // HF APIからフェッチ
    let base_url = std::env::var("HF_BASE_URL")
        .unwrap_or_else(|_| "https://huggingface.co".to_string())
        .trim_end_matches('/')
        .to_string();
    let url = format!("{}/api/models/{}", base_url, repo);

    let mut req = http_client.get(&url);
    if let Ok(token) = std::env::var("HF_TOKEN") {
        req = req.bearer_auth(token);
    }

    let resp = match req.timeout(Duration::from_secs(5)).send().await {
        Ok(r) => r,
        Err(e) => {
            tracing::debug!(repo = %repo, error = %e, "Failed to fetch HF info");
            return None;
        }
    };

    if !resp.status().is_success() {
        tracing::debug!(repo = %repo, status = ?resp.status(), "HF API returned non-success status");
        return None;
    }

    #[derive(Deserialize)]
    struct HfModelInfo {
        downloads: Option<u64>,
        likes: Option<u64>,
    }

    let model_info: HfModelInfo = match resp.json().await {
        Ok(info) => info,
        Err(e) => {
            tracing::debug!(repo = %repo, error = %e, "Failed to parse HF info");
            return None;
        }
    };

    let info = HfInfo {
        downloads: model_info.downloads,
        likes: model_info.likes,
    };

    // キャッシュに保存（ロックポイズニング時はスキップ）
    if let Ok(mut cache) = HF_INFO_CACHE.write() {
        cache.insert(
            repo.to_string(),
            HfInfoCacheEntry {
                fetched_at: Instant::now(),
                info: info.clone(),
            },
        );
    }

    Some(info)
}

/// 対応モデル + 状態（GET /v0/models レスポンス）
#[derive(Debug, Clone, Serialize)]
pub struct ModelWithStatus {
    /// モデルID
    pub id: String,
    /// 表示名
    pub name: String,
    /// 説明
    pub description: String,
    /// HFリポジトリ
    pub repo: String,
    /// 推奨ファイル名
    pub recommended_filename: String,
    /// ファイルサイズ（バイト）
    pub size_bytes: u64,
    /// 必要メモリ（バイト）
    pub required_memory_bytes: u64,
    /// タグ
    pub tags: Vec<String>,
    /// 能力
    pub capabilities: Vec<String>,
    /// 量子化タイプ
    #[serde(skip_serializing_if = "Option::is_none")]
    pub quantization: Option<String>,
    /// パラメータ数
    #[serde(skip_serializing_if = "Option::is_none")]
    pub parameter_count: Option<String>,
    /// モデル状態
    pub status: ModelStatus,
    /// ライフサイクル状態（ダウンロード中/完了時のみ）
    #[serde(skip_serializing_if = "Option::is_none")]
    pub lifecycle_status: Option<LifecycleStatus>,
    /// ダウンロード進捗（ダウンロード中のみ）
    #[serde(skip_serializing_if = "Option::is_none")]
    pub download_progress: Option<DownloadProgress>,
    /// HF動的情報
    #[serde(skip_serializing_if = "Option::is_none")]
    pub hf_info: Option<HfInfo>,
}

impl ModelWithStatus {
    /// 登録済みモデルからModelWithStatusを作成（available状態）
    pub fn from_registered(model: &ModelInfo) -> Self {
        let capabilities = model
            .get_capabilities()
            .iter()
            .map(|cap| format!("{:?}", cap))
            .collect();
        Self {
            id: model.name.clone(),
            name: model.name.clone(),
            description: model.description.clone(),
            repo: model.repo.clone().unwrap_or_default(),
            recommended_filename: model.filename.clone().unwrap_or_default(),
            size_bytes: model.size,
            required_memory_bytes: model.required_memory,
            tags: model.tags.clone(),
            capabilities,
            quantization: None,
            parameter_count: None,
            status: ModelStatus::Available,
            lifecycle_status: Some(LifecycleStatus::Registered),
            download_progress: None,
            hf_info: None,
        }
    }
}

/// ダウンロード進行状況
#[derive(Debug, Clone, Serialize)]
pub struct DownloadProgress {
    /// 進行率（0.0〜1.0）
    pub percent: f64,
    /// ダウンロード済みバイト数
    pub bytes_downloaded: Option<u64>,
    /// 総バイト数
    pub bytes_total: Option<u64>,
    /// エラーメッセージ（status=errorの場合）
    pub error: Option<String>,
}

// NOTE: RegisteredModelView と model_info_to_registered_view は /v0/models 廃止に伴い削除。
// ダッシュボードは /v1/models を使用し、TypeScript側で型を定義。

// NOTE: get_registered_models() ハンドラは廃止されました。
// モデル一覧は /v1/models を使用してください（openai::list_models）。
// LifecycleStatus, DownloadProgress 型は openai.rs で使用するため維持。

/// 登録済みモデル一覧を取得
pub async fn list_registered_models(pool: &SqlitePool) -> RouterResult<Vec<ModelInfo>> {
    let storage = ModelStorage::new(pool.clone());
    storage.load_models().await
}

/// GET /v0/models - 登録済みモデル一覧（拡張メタデータ付き）
///
/// ノード同期用途向け。配列を直接返す。
/// NOTE: この関数は既存のノード同期用途で維持。ダッシュボードは list_models_with_status() を使用。
pub async fn list_models(State(state): State<AppState>) -> Result<Json<Vec<ModelInfo>>, AppError> {
    let models = list_registered_models(&state.db_pool).await?;
    Ok(Json(models))
}

/// GET /v0/models/hub - 登録済みモデル一覧 + 状態（SPEC-6cd7f960 改定版）
///
/// ダッシュボードのModel Hub用。登録済みモデルを状態付きで返す。
/// HF動的情報（ダウンロード数、いいね数）も含む。
///
/// NOTE: supported_models.json は廃止されました (2026-01-25)
/// 現在は登録済みモデルのみを返します。
/// モデルアーキテクチャ認識はエンドポイント側で行われます。
#[allow(deprecated)] // NodeRegistry migration in progress
pub async fn list_models_with_status(
    State(state): State<AppState>,
) -> Result<Json<Vec<ModelWithStatus>>, AppError> {
    let registered = list_registered_models(&state.db_pool).await?;

    // Build ready model names from endpoint models
    let ready_names: std::collections::HashSet<String> = {
        let endpoints = state.endpoint_registry.list().await;
        let mut names = std::collections::HashSet::new();
        for endpoint in &endpoints {
            if let Ok(models) = state.endpoint_registry.list_models(endpoint.id).await {
                for model in models {
                    names.insert(model.model_id.clone());
                }
            }
        }
        names
    };

    // Collect HF repos from registered models
    let hf_repos: std::collections::HashSet<String> =
        registered.iter().filter_map(|m| m.repo.clone()).collect();

    // Collect Hugging Face info for each repo
    let hf_info_futures: Vec<_> = hf_repos
        .into_iter()
        .map(|repo| {
            let client = state.http_client.clone();
            async move { (repo.clone(), fetch_hf_info(&client, &repo).await) }
        })
        .collect();

    let hf_infos: HashMap<String, Option<HfInfo>> = futures::future::join_all(hf_info_futures)
        .await
        .into_iter()
        .collect();

    // Build result from registered models only
    let mut result: Vec<ModelWithStatus> = Vec::with_capacity(registered.len());

    for model in &registered {
        let mut with_status = ModelWithStatus::from_registered(model);
        if ready_names.contains(&model.name) {
            with_status.status = ModelStatus::Downloaded;
        }
        if let Some(repo) = model.repo.as_ref() {
            if let Some(Some(info)) = hf_infos.get(repo) {
                with_status.hf_info = Some(info.clone());
            }
        }
        result.push(with_status);
    }

    Ok(Json(result))
}

/// 登録済みモデルを名前で取得
pub async fn load_registered_model(
    pool: &SqlitePool,
    name: &str,
) -> RouterResult<Option<ModelInfo>> {
    let storage = ModelStorage::new(pool.clone());
    storage.load_model(name).await
}

// ===== HuggingFace helpers =====

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum ArtifactFormat {
    Gguf,
    Safetensors,
}

struct ArtifactSelection {
    format: ArtifactFormat,
    filename: String,
}

fn hf_base_url() -> String {
    std::env::var("HF_BASE_URL")
        .unwrap_or_else(|_| "https://huggingface.co".to_string())
        .trim_end_matches('/')
        .to_string()
}

fn hf_resolve_url(base_url: &str, repo: &str, filename: &str) -> String {
    format!("{}/{}/resolve/main/{}", base_url, repo, filename)
}

async fn fetch_repo_siblings(
    http_client: &reqwest::Client,
    repo: &str,
) -> Result<Vec<HfSibling>, LbError> {
    let base_url = hf_base_url();
    let url = format!("{}/api/models/{}?expand=siblings", base_url, repo);

    let mut req = http_client.get(&url);
    if let Ok(token) = std::env::var("HF_TOKEN") {
        req = req.bearer_auth(token);
    }
    let resp = req.send().await.map_err(|e| LbError::Http(e.to_string()))?;
    if !resp.status().is_success() {
        return Err(LbError::Common(CommonError::Validation(
            "Failed to fetch specified repository".into(),
        )));
    }
    #[derive(Deserialize)]
    struct RepoDetail {
        siblings: Vec<HfSibling>,
    }
    let detail: RepoDetail = resp
        .json()
        .await
        .map_err(|e| LbError::Http(e.to_string()))?;
    Ok(detail.siblings)
}

async fn fetch_hf_file_bytes(
    http_client: &reqwest::Client,
    repo: &str,
    filename: &str,
) -> Result<Vec<u8>, LbError> {
    let base_url = hf_base_url();
    let url = hf_resolve_url(&base_url, repo, filename);
    let mut req = http_client.get(&url);
    if let Ok(token) = std::env::var("HF_TOKEN") {
        req = req.bearer_auth(token);
    }
    let resp = req.send().await.map_err(|e| LbError::Http(e.to_string()))?;
    if !resp.status().is_success() {
        return Err(LbError::Common(CommonError::Validation(format!(
            "Failed to fetch file: {}",
            filename
        ))));
    }
    let bytes = resp
        .bytes()
        .await
        .map_err(|e| LbError::Http(e.to_string()))?;
    Ok(bytes.to_vec())
}

fn is_gguf_filename(filename: &str) -> bool {
    filename.to_ascii_lowercase().ends_with(".gguf")
}

fn is_safetensors_index_filename(filename: &str) -> bool {
    filename
        .to_ascii_lowercase()
        .ends_with(".safetensors.index.json")
}

fn is_safetensors_filename(filename: &str) -> bool {
    let lower = filename.to_ascii_lowercase();
    lower.ends_with(".safetensors") || lower.ends_with(".safetensors.index.json")
}

fn infer_safetensors_index_from_shard(filename: &str) -> Option<String> {
    if is_safetensors_index_filename(filename) {
        return None;
    }
    if !filename.to_ascii_lowercase().ends_with(".safetensors") {
        return None;
    }

    let (dir, file) = match filename.rsplit_once('/') {
        Some((dir, file)) => (format!("{}/", dir), file),
        None => ("".to_string(), filename),
    };

    let stem = file.strip_suffix(".safetensors")?;
    let (left, total) = stem.rsplit_once("-of-")?;
    if left.is_empty() || total.is_empty() {
        return None;
    }
    if !total.chars().all(|c| c.is_ascii_digit()) {
        return None;
    }
    let (prefix, shard) = left.rsplit_once('-')?;
    if prefix.is_empty() || shard.is_empty() {
        return None;
    }
    if !shard.chars().all(|c| c.is_ascii_digit()) {
        return None;
    }

    Some(format!("{}{}.safetensors.index.json", dir, prefix))
}

fn sibling_size_bytes(s: &HfSibling) -> u64 {
    s.size
        .or_else(|| s.lfs.as_ref().and_then(|l| l.size))
        .unwrap_or(0)
}

fn has_sibling(siblings: &[HfSibling], filename: &str) -> bool {
    siblings.iter().any(|s| s.rfilename == filename)
}

fn require_safetensors_metadata_files(siblings: &[HfSibling]) -> Result<(), LbError> {
    let has_config = has_sibling(siblings, "config.json");
    let has_tokenizer = has_sibling(siblings, "tokenizer.json");
    if !has_config || !has_tokenizer {
        return Err(LbError::Common(CommonError::Validation(
            "config.json and tokenizer.json are required for safetensors models".into(),
        )));
    }
    Ok(())
}

fn resolve_primary_artifact(
    siblings: &[HfSibling],
    filename_hint: Option<String>,
) -> Result<ArtifactSelection, LbError> {
    if let Some(filename) = filename_hint {
        if !has_sibling(siblings, &filename) {
            return Err(LbError::Common(CommonError::Validation(
                "Specified file not found in repository".into(),
            )));
        }
        if is_gguf_filename(&filename) {
            return Ok(ArtifactSelection {
                format: ArtifactFormat::Gguf,
                filename,
            });
        }
        if is_safetensors_filename(&filename) {
            require_safetensors_metadata_files(siblings)?;
            let resolved = resolve_safetensors_primary(siblings, Some(filename))?;
            return Ok(ArtifactSelection {
                format: ArtifactFormat::Safetensors,
                filename: resolved,
            });
        }
        return Err(LbError::Common(CommonError::Validation(
            "filename must be a .gguf or .safetensors file".into(),
        )));
    }

    let ggufs: Vec<_> = siblings
        .iter()
        .filter(|s| is_gguf_filename(&s.rfilename))
        .map(|s| s.rfilename.clone())
        .collect();
    let safetensors: Vec<_> = siblings
        .iter()
        .filter(|s| is_safetensors_filename(&s.rfilename))
        .map(|s| s.rfilename.clone())
        .collect();

    if !ggufs.is_empty() && !safetensors.is_empty() {
        return Err(LbError::Common(CommonError::Validation(
            "Multiple artifact types found; specify filename".into(),
        )));
    }

    if !ggufs.is_empty() {
        if ggufs.len() == 1 {
            return Ok(ArtifactSelection {
                format: ArtifactFormat::Gguf,
                filename: ggufs[0].clone(),
            });
        }
        return Err(LbError::Common(CommonError::Validation(
            "Multiple GGUF files found; specify filename".into(),
        )));
    }

    if !safetensors.is_empty() {
        require_safetensors_metadata_files(siblings)?;
        let filename = resolve_safetensors_primary(siblings, None)?;
        return Ok(ArtifactSelection {
            format: ArtifactFormat::Safetensors,
            filename,
        });
    }

    Err(LbError::Common(CommonError::Validation(
        "No supported model artifacts found (safetensors/gguf)".into(),
    )))
}

fn extract_runtime_from_config(value: &serde_json::Value) -> Option<String> {
    if let Some(arr) = value.get("architectures").and_then(|x| x.as_array()) {
        for a in arr {
            let Some(s) = a.as_str() else { continue };
            if s.contains("GptOss") || s.contains("GPTOSS") {
                return Some("gptoss_cpp".to_string());
            }
            if s.contains("Nemotron") {
                return Some("nemotron_cpp".to_string());
            }
        }
    }

    if let Some(mt) = value.get("model_type").and_then(|x| x.as_str()) {
        let mt = mt.to_ascii_lowercase();
        if mt.contains("gpt_oss") || mt.contains("gptoss") {
            return Some("gptoss_cpp".to_string());
        }
        if mt.contains("nemotron") {
            return Some("nemotron_cpp".to_string());
        }
    }
    None
}

async fn infer_runtime_hint(http_client: &reqwest::Client, repo: &str) -> Option<Vec<String>> {
    if !repo.is_empty() {
        if let Ok(bytes) = fetch_hf_file_bytes(http_client, repo, "config.json").await {
            if let Ok(v) = serde_json::from_slice::<serde_json::Value>(&bytes) {
                if let Some(rt) = extract_runtime_from_config(&v) {
                    return Some(vec![rt]);
                }
            }
        }
    }
    None
}

async fn fetch_safetensors_index_shards(
    http_client: &reqwest::Client,
    repo: &str,
    index_filename: &str,
) -> Result<Vec<String>, LbError> {
    let bytes = fetch_hf_file_bytes(http_client, repo, index_filename).await?;
    let value: serde_json::Value =
        serde_json::from_slice(&bytes).map_err(|e| LbError::Http(e.to_string()))?;
    let Some(map) = value.get("weight_map").and_then(|v| v.as_object()) else {
        return Err(LbError::Common(CommonError::Validation(
            "Invalid safetensors index format".into(),
        )));
    };
    let mut shards: std::collections::HashSet<String> = std::collections::HashSet::new();
    for v in map.values() {
        if let Some(s) = v.as_str() {
            shards.insert(s.to_string());
        }
    }
    let mut list: Vec<String> = shards.into_iter().collect();
    list.sort();
    Ok(list)
}

fn find_metal_artifact(siblings: &[HfSibling]) -> Option<String> {
    let candidates = ["model.metal.bin", "metal/model.bin"];
    for name in candidates {
        if has_sibling(siblings, name) {
            return Some(name.to_string());
        }
    }
    None
}

fn validate_artifact_path(path: &str) -> Result<(), LbError> {
    if path.is_empty() {
        return Err(LbError::Common(CommonError::Validation(
            "filename must not be empty".into(),
        )));
    }
    if path.contains("..") || path.contains('\0') {
        return Err(LbError::Common(CommonError::Validation(
            "filename contains invalid path segment".into(),
        )));
    }
    if path.starts_with('/') || path.starts_with('\\') {
        return Err(LbError::Common(CommonError::Validation(
            "filename must be a relative path".into(),
        )));
    }
    Ok(())
}

fn extract_filename_from_hf_url(input: &str) -> Option<String> {
    for marker in ["/resolve/", "/blob/", "/raw/"] {
        if let Some(rest) = input.split(marker).nth(1) {
            let mut parts = rest.splitn(2, '/');
            let _revision = parts.next();
            if let Some(path) = parts.next() {
                if !path.is_empty() {
                    return Some(path.to_string());
                }
            }
        }
    }
    None
}

#[derive(Serialize)]
struct ManifestFile {
    name: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    priority: Option<i32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    runtimes: Option<Vec<String>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    url: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    optional: Option<bool>,
}

#[derive(Serialize)]
struct Manifest {
    format: String,
    files: Vec<ManifestFile>,
    #[serde(skip_serializing_if = "Option::is_none")]
    quantization: Option<String>,
}

fn manifest_format_label(format: ArtifactFormat) -> &'static str {
    match format {
        ArtifactFormat::Gguf => "gguf",
        ArtifactFormat::Safetensors => "safetensors",
    }
}

fn manifest_file_priority(name: &str) -> Option<i32> {
    match name {
        "config.json" | "tokenizer.json" => Some(10),
        _ if is_safetensors_index_filename(name) => Some(5),
        "model.metal.bin" => Some(5),
        _ => None,
    }
}

fn is_quantization_token(token: &str) -> bool {
    if token.is_empty() {
        return false;
    }
    if !token.chars().all(|c| c.is_ascii_alphanumeric() || c == '_') {
        return false;
    }
    let upper = token.to_ascii_uppercase();
    let has_digit = |s: &str| s.chars().any(|c| c.is_ascii_digit());
    let starts_with_digit = |s: &str| s.chars().next().is_some_and(|c| c.is_ascii_digit());

    if let Some(rest) = upper.strip_prefix("IQ") {
        return starts_with_digit(rest);
    }
    if let Some(rest) = upper.strip_prefix('Q') {
        return starts_with_digit(rest);
    }
    if let Some(rest) = upper.strip_prefix("BF") {
        return starts_with_digit(rest);
    }
    if let Some(rest) = upper.strip_prefix("FP") {
        return starts_with_digit(rest);
    }
    if let Some(rest) = upper.strip_prefix('F') {
        return starts_with_digit(rest);
    }
    if let Some(rest) = upper.strip_prefix("MX") {
        return has_digit(rest);
    }
    false
}

fn infer_quantization_from_filename(filename: &str) -> Option<String> {
    let file = std::path::Path::new(filename)
        .file_name()?
        .to_string_lossy();
    if !file.to_ascii_lowercase().ends_with(".gguf") {
        return None;
    }
    let stem = file.strip_suffix(".gguf").unwrap_or(&file);
    for token in stem.split(['-', '.']).rev() {
        if is_quantization_token(token) {
            return Some(token.to_string());
        }
    }
    None
}
fn resolve_safetensors_primary(
    siblings: &[HfSibling],
    requested: Option<String>,
) -> Result<String, LbError> {
    if let Some(filename) = requested {
        if !is_safetensors_filename(&filename) {
            return Err(LbError::Common(CommonError::Validation(
                "filename must be a safetensors or safetensors index file".into(),
            )));
        }
        if !has_sibling(siblings, &filename) {
            return Err(LbError::Common(CommonError::Validation(
                "Specified safetensors file not found in repository".into(),
            )));
        }
        if !is_safetensors_index_filename(&filename) {
            if let Some(candidate) = infer_safetensors_index_from_shard(&filename) {
                if has_sibling(siblings, &candidate) {
                    return Ok(candidate);
                }
                let index_files: Vec<_> = siblings
                    .iter()
                    .map(|s| s.rfilename.clone())
                    .filter(|f| is_safetensors_index_filename(f))
                    .collect();
                if index_files.len() == 1 {
                    return Ok(index_files[0].clone());
                }
                if index_files.len() > 1 {
                    return Err(LbError::Common(CommonError::Validation(
                        "Multiple safetensors index files found; specify filename".into(),
                    )));
                }
            }
        }
        return Ok(filename);
    }

    let index_files: Vec<_> = siblings
        .iter()
        .map(|s| s.rfilename.clone())
        .filter(|f| is_safetensors_index_filename(f))
        .collect();
    if index_files.len() == 1 {
        return Ok(index_files[0].clone());
    }
    if index_files.len() > 1 {
        return Err(LbError::Common(CommonError::Validation(
            "Multiple safetensors index files found; specify filename".into(),
        )));
    }

    let st_files: Vec<_> = siblings
        .iter()
        .map(|s| s.rfilename.clone())
        .filter(|f| {
            // .safetensors だが index は除外
            f.to_ascii_lowercase().ends_with(".safetensors") && !is_safetensors_index_filename(f)
        })
        .collect();
    if st_files.len() == 1 {
        return Ok(st_files[0].clone());
    }
    if st_files.is_empty() {
        return Err(LbError::Common(CommonError::Validation(
            "No safetensors file found in repository".into(),
        )));
    }
    Err(LbError::Common(CommonError::Validation(
        "Multiple safetensors files found; specify filename".into(),
    )))
}

/// HuggingFaceのtokenizer_config.jsonからchat_templateを取得
async fn fetch_chat_template_from_hf(http_client: &reqwest::Client, repo: &str) -> Option<String> {
    let base_url = std::env::var("HF_BASE_URL")
        .unwrap_or_else(|_| "https://huggingface.co".to_string())
        .trim_end_matches('/')
        .to_string();
    let url = format!("{}/{}/resolve/main/tokenizer_config.json", base_url, repo);

    let mut req = http_client.get(&url);
    if let Ok(token) = std::env::var("HF_TOKEN") {
        req = req.bearer_auth(token);
    }

    match req.send().await {
        Ok(resp) if resp.status().is_success() => {
            if let Ok(json) = resp.json::<serde_json::Value>().await {
                let template = json
                    .get("chat_template")
                    .and_then(|v| v.as_str())
                    .map(|s| s.to_string());
                if template.is_some() {
                    tracing::info!(repo = %repo, "chat_template fetched from tokenizer_config.json");
                }
                template
            } else {
                tracing::debug!(repo = %repo, "Failed to parse tokenizer_config.json");
                None
            }
        }
        Ok(resp) => {
            tracing::debug!(repo = %repo, status = ?resp.status(), "tokenizer_config.json not found");
            None
        }
        Err(e) => {
            tracing::debug!(repo = %repo, error = %e, "Failed to fetch tokenizer_config.json");
            None
        }
    }
}

/// 登録モデルを全削除（テスト用）
pub async fn clear_registered_models(pool: &SqlitePool) -> RouterResult<()> {
    let mut tx = pool
        .begin()
        .await
        .map_err(|e| LbError::Database(format!("Failed to begin transaction: {}", e)))?;

    sqlx::query("DELETE FROM model_tags")
        .execute(&mut *tx)
        .await
        .map_err(|e| LbError::Database(format!("Failed to delete model_tags: {}", e)))?;
    sqlx::query("DELETE FROM model_capabilities")
        .execute(&mut *tx)
        .await
        .map_err(|e| LbError::Database(format!("Failed to delete model_capabilities: {}", e)))?;
    sqlx::query("DELETE FROM models")
        .execute(&mut *tx)
        .await
        .map_err(|e| LbError::Database(format!("Failed to delete models: {}", e)))?;

    tx.commit()
        .await
        .map_err(|e| LbError::Database(format!("Failed to commit transaction: {}", e)))?;

    Ok(())
}

/// HFリポジトリのsiblings情報
#[derive(Deserialize)]
struct HfSibling {
    #[serde(rename = "rfilename")]
    rfilename: String,
    /// ファイルサイズ（オプション）
    #[serde(default)]
    size: Option<u64>,
    /// LFS情報（オプション）
    lfs: Option<HfLfs>,
}

/// HF LFS情報
#[derive(Deserialize)]
struct HfLfs {
    /// ファイルサイズ
    size: Option<u64>,
}

/// Axum用のエラーレスポンス型
#[derive(Debug)]
pub struct AppError(LbError);

impl From<LbError> for AppError {
    fn from(err: LbError) -> Self {
        AppError(err)
    }
}

impl IntoResponse for AppError {
    fn into_response(self) -> axum::response::Response {
        let (status, message) = match &self.0 {
            LbError::NodeNotFound(_) => (StatusCode::NOT_FOUND, self.0.to_string()),
            LbError::NoNodesAvailable => (StatusCode::SERVICE_UNAVAILABLE, self.0.to_string()),
            LbError::ServiceUnavailable(msg) => (StatusCode::SERVICE_UNAVAILABLE, msg.clone()),
            LbError::NodeOffline(_) => (StatusCode::SERVICE_UNAVAILABLE, self.0.to_string()),
            LbError::InvalidModelName(_) => (StatusCode::BAD_REQUEST, self.0.to_string()),
            LbError::InsufficientStorage(_) => {
                (StatusCode::INSUFFICIENT_STORAGE, self.0.to_string())
            }
            LbError::Database(_) => (StatusCode::INTERNAL_SERVER_ERROR, self.0.to_string()),
            LbError::Http(_) => (StatusCode::BAD_GATEWAY, self.0.to_string()),
            LbError::Timeout(_) => (StatusCode::GATEWAY_TIMEOUT, self.0.to_string()),
            LbError::Internal(_) => (StatusCode::INTERNAL_SERVER_ERROR, self.0.to_string()),
            LbError::PasswordHash(_) => (StatusCode::INTERNAL_SERVER_ERROR, self.0.to_string()),
            LbError::Jwt(_) => (StatusCode::INTERNAL_SERVER_ERROR, self.0.to_string()),
            LbError::Authentication(_) => (StatusCode::UNAUTHORIZED, self.0.to_string()),
            LbError::Authorization(_) => (StatusCode::FORBIDDEN, self.0.to_string()),
            LbError::NoCapableNodes(_) => (StatusCode::SERVICE_UNAVAILABLE, self.0.to_string()),
            LbError::Common(err) => (StatusCode::BAD_REQUEST, err.to_string()),
        };

        (status, Json(serde_json::json!({ "error": message }))).into_response()
    }
}

// NOTE: GET /v0/models/available は廃止されました。
// HFカタログは直接 https://huggingface.co を参照してください。

#[derive(Deserialize)]
/// HFモデル登録リクエスト
pub struct RegisterModelRequest {
    /// HFリポジトリ名 (e.g., TheBloke/Llama-2-7B-GGUF)
    pub repo: String,
    /// ファイル名 (e.g., llama-2-7b.Q4_K_M.gguf)
    pub filename: Option<String>,
    /// 表示名（任意）
    #[serde(default)]
    pub display_name: Option<String>,
    /// オプションのchat_template（GGUFに含まれない場合の補助）
    #[serde(default)]
    pub chat_template: Option<String>,
}

async fn compute_gpu_warnings(
    registry: &crate::registry::endpoints::EndpointRegistry,
    required_memory: u64,
) -> Vec<String> {
    let mut warnings = Vec::new();
    if required_memory == 0 {
        return warnings;
    }

    let endpoints = registry.list().await;
    let mut memories: Vec<u64> = Vec::new();
    for endpoint in endpoints {
        if let Some(mem) = endpoint.gpu_total_memory_bytes {
            memories.push(mem);
        }
    }

    // 安全: max()はSomeを返すことが保証（空でないことを上でチェック済み）
    let Some(max_mem) = memories.iter().max().copied() else {
        warnings.push("No GPU memory info available from registered endpoints".into());
        return warnings;
    };

    if required_memory > max_mem {
        warnings.push(format!(
            "Model requires {:.1}GB but max endpoint GPU memory is {:.1}GB",
            required_memory as f64 / (1024.0 * 1024.0 * 1024.0),
            max_mem as f64 / (1024.0 * 1024.0 * 1024.0),
        ));
    }

    warnings
}

/// POST /v0/models/register - HFモデルを対応モデルに登録（メタデータのみ）
///
/// 方針:
/// - ルーターは変換・バイナリ保存を行わない
/// - `filename` を指定するとそのアーティファクトを主として登録
/// - 未指定の場合、リポジトリ内のアーティファクトが一意であれば自動選択
/// - safetensors では `config.json` / `tokenizer.json` が必須
#[allow(deprecated)] // NodeRegistry migration in progress
pub async fn register_model(
    State(state): State<AppState>,
    Json(req): Json<RegisterModelRequest>,
) -> Result<(StatusCode, Json<serde_json::Value>), AppError> {
    if req.repo.trim().is_empty() {
        return Err(LbError::Common(CommonError::Validation("repo is required".into())).into());
    }

    // URLからrepo_idを抽出（フルURLが渡された場合はrepo_id形式に正規化）
    let repo = extract_repo_id(&req.repo);

    let name = generate_model_id(&repo);
    if load_registered_model(&state.db_pool, &name)
        .await?
        .is_some()
    {
        return Err(
            LbError::Common(CommonError::Validation("Model already registered".into())).into(),
        );
    }

    let filename_hint = req
        .filename
        .clone()
        .or_else(|| extract_filename_from_hf_url(&req.repo));

    if let Some(fname) = filename_hint.as_ref() {
        validate_artifact_path(fname)?;
    }

    let siblings = fetch_repo_siblings(&state.http_client, &repo).await?;
    let selection = resolve_primary_artifact(&siblings, filename_hint)?;

    let (content_length, required_memory, warnings) = {
        let (size, required) = match selection.format {
            ArtifactFormat::Gguf => {
                let size = siblings
                    .iter()
                    .find(|s| s.rfilename == selection.filename)
                    .map(sibling_size_bytes)
                    .unwrap_or(0);
                const REQUIRED_MEMORY_RATIO: f64 = 1.5;
                let required = if size > 0 {
                    ((size as f64) * REQUIRED_MEMORY_RATIO).ceil() as u64
                } else {
                    0
                };
                (size, required)
            }
            ArtifactFormat::Safetensors => {
                let total = siblings
                    .iter()
                    .filter(|s| s.rfilename.to_ascii_lowercase().ends_with(".safetensors"))
                    .map(sibling_size_bytes)
                    .sum::<u64>();
                const REQUIRED_MEMORY_RATIO: f64 = 1.5;
                let required = if total > 0 {
                    ((total as f64) * REQUIRED_MEMORY_RATIO).ceil() as u64
                } else {
                    0
                };
                (total, required)
            }
        };
        let warnings = compute_gpu_warnings(&state.endpoint_registry, required).await;
        (size, required, warnings)
    };

    let chat_template = if req.chat_template.is_some() {
        req.chat_template.clone()
    } else {
        fetch_chat_template_from_hf(&state.http_client, &repo).await
    };

    let mut tags = Vec::new();
    match selection.format {
        ArtifactFormat::Gguf => tags.push("gguf".to_string()),
        ArtifactFormat::Safetensors => tags.push("safetensors".to_string()),
    }
    let description = req.display_name.clone().unwrap_or_else(|| repo.clone());
    let capabilities = vec![crate::common::types::ModelCapability::TextGeneration];
    let size_bytes = content_length;
    let required_memory_bytes = required_memory;

    let source = match selection.format {
        ArtifactFormat::Gguf => crate::registry::models::ModelSource::HfGguf,
        ArtifactFormat::Safetensors => crate::registry::models::ModelSource::HfSafetensors,
    };

    let model = ModelInfo {
        name: name.clone(),
        size: size_bytes,
        description,
        required_memory: required_memory_bytes,
        tags,
        capabilities,
        source,
        chat_template,
        repo: Some(repo.clone()),
        filename: Some(selection.filename.clone()),
        last_modified: None,
        status: Some("registered".to_string()),
    };

    let storage = ModelStorage::new(state.db_pool.clone());
    storage.save_model(&model).await?;

    tracing::info!(
        repo = %repo,
        filename = %selection.filename,
        size_bytes = content_length,
        required_memory_bytes = required_memory,
        warnings = warnings.len(),
        "hf_model_registered"
    );

    let response = serde_json::json!({
        "name": name,
        "status": "registered",
        "filename": selection.filename,
        "size_bytes": content_length,
        "required_memory_bytes": required_memory,
        "warnings": warnings,
    });

    Ok((StatusCode::CREATED, Json(response)))
}

/// DELETE /v0/models/:model_name - 登録モデル削除
///
/// 登録情報のみ削除し、Nodeは次回同期でキャッシュを削除する。
pub async fn delete_model(
    State(state): State<AppState>,
    Path(model_name): Path<String>,
) -> Result<StatusCode, AppError> {
    let storage = ModelStorage::new(state.db_pool.clone());
    if storage.load_model(&model_name).await?.is_none() {
        return Err(LbError::Common(CommonError::Validation("model not found".into())).into());
    }
    storage.delete_model(&model_name).await?;
    Ok(StatusCode::NO_CONTENT)
}

/// GET /v0/models/registry/:model_name/manifest.json - モデル配布マニフェスト
///
/// Node がモデルを複数ファイル（safetensors + metadata）として取得するためのマニフェスト。
pub async fn get_model_registry_manifest(
    State(state): State<AppState>,
    Path(model_name): Path<String>,
) -> axum::response::Response {
    use axum::body::Body;
    use axum::response::Response;

    // エラーレスポンスを作成するヘルパー（Response::builder()はこの用途では失敗しない）
    fn error_response(status: StatusCode, message: &str) -> Response {
        Response::builder()
            .status(status)
            .body(Body::from(format!("{{\"error\": \"{}\"}}", message)))
            .expect("Response builder should not fail with valid status and string body")
    }

    if let Err(e) = validate_model_name(&model_name) {
        return error_response(StatusCode::BAD_REQUEST, &e.to_string());
    }

    let model = match load_registered_model(&state.db_pool, &model_name).await {
        Ok(Some(m)) => m,
        Ok(None) => {
            return error_response(
                StatusCode::NOT_FOUND,
                &format!("Model not found: {}", model_name),
            );
        }
        Err(e) => {
            return error_response(StatusCode::INTERNAL_SERVER_ERROR, &e.to_string());
        }
    };

    let Some(repo) = model.repo.clone() else {
        return error_response(StatusCode::BAD_REQUEST, "repo not set for model");
    };

    let siblings = match fetch_repo_siblings(&state.http_client, &repo).await {
        Ok(list) => list,
        Err(e) => {
            return error_response(StatusCode::BAD_GATEWAY, &e.to_string());
        }
    };

    let selection = match resolve_primary_artifact(&siblings, model.filename.clone()) {
        Ok(sel) => sel,
        Err(e) => {
            return error_response(StatusCode::BAD_REQUEST, &e.to_string());
        }
    };

    let runtime_hint = match selection.format {
        ArtifactFormat::Gguf => Some(vec!["llama_cpp".to_string()]),
        ArtifactFormat::Safetensors => infer_runtime_hint(&state.http_client, &repo)
            .await
            .or_else(|| Some(vec!["safetensors_cpp".to_string()])),
    };
    let manifest_quantization = match selection.format {
        ArtifactFormat::Gguf => infer_quantization_from_filename(&selection.filename),
        ArtifactFormat::Safetensors => None,
    };

    let base_url = hf_base_url();
    let mut files: Vec<ManifestFile> = Vec::new();

    match selection.format {
        ArtifactFormat::Gguf => {
            files.push(ManifestFile {
                name: "model.gguf".to_string(),
                priority: None,
                runtimes: runtime_hint.clone(),
                url: Some(hf_resolve_url(&base_url, &repo, &selection.filename)),
                optional: None,
            });
        }
        ArtifactFormat::Safetensors => {
            if let Err(e) = require_safetensors_metadata_files(&siblings) {
                return error_response(StatusCode::BAD_REQUEST, &e.to_string());
            }

            let mut names: Vec<String> =
                vec!["config.json".to_string(), "tokenizer.json".to_string()];
            names.push(selection.filename.clone());

            if is_safetensors_index_filename(&selection.filename) {
                match fetch_safetensors_index_shards(&state.http_client, &repo, &selection.filename)
                    .await
                {
                    Ok(shards) => {
                        for shard in shards {
                            if !names.contains(&shard) {
                                names.push(shard);
                            }
                        }
                    }
                    Err(e) => {
                        return error_response(StatusCode::BAD_REQUEST, &e.to_string());
                    }
                }
            }

            for name in names {
                files.push(ManifestFile {
                    name: name.clone(),
                    priority: manifest_file_priority(&name),
                    runtimes: runtime_hint.clone(),
                    url: Some(hf_resolve_url(&base_url, &repo, &name)),
                    optional: None,
                });
            }
        }
    }

    if let Some(metal_path) = find_metal_artifact(&siblings) {
        files.push(ManifestFile {
            name: "model.metal.bin".to_string(),
            priority: manifest_file_priority("model.metal.bin"),
            runtimes: runtime_hint.clone(),
            url: Some(hf_resolve_url(&base_url, &repo, &metal_path)),
            optional: None,
        });
    }

    let body = serde_json::to_string(&Manifest {
        format: manifest_format_label(selection.format).to_string(),
        files,
        quantization: manifest_quantization,
    })
    .unwrap_or_else(|_| "{\"format\":\"unknown\",\"files\":[]}".into());
    Response::builder()
        .status(StatusCode::OK)
        .header(axum::http::header::CONTENT_TYPE, "application/json")
        .body(Body::from(body))
        .expect("Response builder should not fail with valid status and string body")
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_validate_model_name_valid() {
        assert!(validate_model_name("gpt-oss").is_ok());
        assert!(validate_model_name("gpt-oss-7b").is_ok());
        assert!(validate_model_name("llama3.2").is_ok());
        assert!(validate_model_name("model_name-v1.0").is_ok());
    }

    #[test]
    fn test_validate_model_name_hierarchical_valid() {
        // SPEC-dcaeaec4 FR-2: 階層形式を許可
        assert!(validate_model_name("openai/gpt-oss-20b").is_ok());
        assert!(validate_model_name("meta/llama-3-8b").is_ok());
        assert!(validate_model_name("org/sub/model").is_ok());
    }

    #[test]
    fn test_validate_model_name_empty() {
        assert!(validate_model_name("").is_err());
    }

    #[test]
    fn test_validate_model_name_colon_rejected() {
        assert!(validate_model_name("llama3.2:latest").is_err());
    }

    #[test]
    fn test_validate_model_name_invalid_characters() {
        assert!(validate_model_name("Model Name").is_err());
        assert!(validate_model_name("model@name").is_err());
    }

    #[test]
    fn test_validate_model_name_dangerous_patterns_rejected() {
        // パストラバーサル対策
        assert!(validate_model_name("../etc/passwd").is_err());
        assert!(validate_model_name("model/../other").is_err());
        assert!(validate_model_name("/absolute/path").is_err());
        assert!(validate_model_name("trailing/").is_err());
    }

    // NOTE: compute_gpu_warnings は SPEC-6cd7f960 で廃止されました

    // ===== SPEC-6cd7f960: 対応モデルリスト型管理 =====

    #[test]
    fn test_model_status_serialization() {
        // ModelStatusが正しくシリアライズされることを確認
        assert_eq!(
            serde_json::to_string(&ModelStatus::Available).unwrap(),
            "\"available\""
        );
        assert_eq!(
            serde_json::to_string(&ModelStatus::Downloading).unwrap(),
            "\"downloading\""
        );
        assert_eq!(
            serde_json::to_string(&ModelStatus::Downloaded).unwrap(),
            "\"downloaded\""
        );
    }

    #[test]
    fn test_model_with_status_from_registered() {
        let mut model = ModelInfo::new(
            "test-model".to_string(),
            1000,
            "Test Model".to_string(),
            1500,
            vec!["test".to_string()],
        );
        model.repo = Some("test/repo".into());
        model.filename = Some("model.gguf".into());

        let with_status = ModelWithStatus::from_registered(&model);

        assert_eq!(with_status.id, "test-model");
        assert_eq!(with_status.name, "test-model");
        assert_eq!(with_status.description, "Test Model");
        assert_eq!(with_status.status, ModelStatus::Available);
        assert_eq!(
            with_status.lifecycle_status,
            Some(LifecycleStatus::Registered)
        );
        assert!(with_status.download_progress.is_none());
        assert!(with_status.hf_info.is_none());
    }

    #[test]
    fn test_model_with_status_serialization() {
        let mut model = ModelInfo::new(
            "qwen2.5-7b-instruct".to_string(),
            4_920_000_000,
            "Qwen2.5 7B Instruct".to_string(),
            7_380_000_000,
            vec!["chat".to_string()],
        );
        model.repo = Some("bartowski/Qwen2.5-7B-Instruct-GGUF".into());
        model.filename = Some("Qwen2.5-7B-Instruct-Q4_K_M.gguf".into());

        let with_status = ModelWithStatus::from_registered(&model);
        let json = serde_json::to_string(&with_status).expect("シリアライズに失敗");

        // JSONに必要なフィールドが含まれることを確認
        assert!(json.contains("\"id\":\"qwen2.5-7b-instruct\""));
        assert!(json.contains("\"status\":\"available\""));
        assert!(json.contains("\"lifecycle_status\":\"registered\""));
        // skip_serializing_if により None フィールドは含まれない
        assert!(!json.contains("\"download_progress\""));
    }

    #[test]
    fn test_hf_info_serialization() {
        let hf_info = HfInfo {
            downloads: Some(125000),
            likes: Some(450),
        };
        let json = serde_json::to_string(&hf_info).expect("シリアライズに失敗");
        assert!(json.contains("\"downloads\":125000"));
        assert!(json.contains("\"likes\":450"));

        // Noneの場合はフィールドが省略される
        let empty_info = HfInfo::default();
        let empty_json = serde_json::to_string(&empty_info).expect("シリアライズに失敗");
        assert_eq!(empty_json, "{}");
    }
}
