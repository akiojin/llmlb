{
  "engine_id": "llama_cpp",
  "engine_version": "0.1.0",
  "abi_version": 2,
  "runtimes": ["llama_cpp"],
  "formats": ["gguf"],
  "architectures": ["llama", "mistral", "gemma", "phi"],
  "capabilities": ["text", "embeddings"],
  "gpu_targets": ["metal", "cuda"],
  "library": "llm_engine_llama_cpp"
}
