//! REST APIハンドラー
//!
//! ノード登録、ヘルスチェック、プロキシAPI

pub mod api_keys;
pub mod audio;
pub mod auth;
pub mod dashboard;
pub mod health;
pub mod images;
pub mod logs;
pub mod models;
pub mod nodes;
pub mod openai;
pub mod proxy;
pub mod users;

use crate::cloud_metrics;
use crate::AppState;
use axum::{
    body::Body,
    extract::Path as AxumPath,
    http::{header, StatusCode},
    middleware,
    response::{IntoResponse, Response},
    routing::{delete, get, post, put},
    Router,
};
use include_dir::{include_dir, Dir, File};
use mime_guess::MimeGuess;

static DASHBOARD_ASSETS: Dir = include_dir!("$CARGO_MANIFEST_DIR/src/web/static");
const DASHBOARD_INDEX: &str = "index.html";
const PLAYGROUND_INDEX: &str = "playground.html";
// Force rebuild when embedded dashboard/playground assets change.
// The file is generated by `router/build.rs`.
const _DASHBOARD_ASSETS_BUILD_STAMP: &str = include_str!(concat!(
    env!("OUT_DIR"),
    "/dashboard_assets_build_stamp.txt"
));

/// APIルーターを作成
pub fn create_router(state: AppState) -> Router {
    // `/v0/*`: llm-router独自API（管理/運用向け）
    // JWT認証が必要な保護されたルート
    let protected_routes = Router::new()
        .route("/auth/me", get(auth::me))
        .route("/users", get(users::list_users).post(users::create_user))
        .route(
            "/users/:id",
            put(users::update_user).delete(users::delete_user),
        )
        .route("/nodes/:node_id/approve", post(nodes::approve_node))
        .route(
            "/api-keys",
            get(api_keys::list_api_keys).post(api_keys::create_api_key),
        )
        .route(
            "/api-keys/:id",
            put(api_keys::update_api_key).delete(api_keys::delete_api_key),
        )
        .layer(middleware::from_fn_with_state(
            state.jwt_secret.clone(),
            crate::auth::middleware::jwt_auth_middleware,
        ));

    // ノードトークン認証が必要なルート
    let node_protected_routes = Router::new()
        .route("/health", post(health::health_check))
        .layer(middleware::from_fn_with_state(
            state.db_pool.clone(),
            crate::auth::middleware::node_token_auth_middleware,
        ));

    // APIキー認証が必要なルート（OpenAI互換エンドポイント）
    let api_key_routes = Router::new()
        .route("/v1/chat/completions", post(openai::chat_completions))
        .route("/v1/completions", post(openai::completions))
        .route("/v1/embeddings", post(openai::embeddings))
        // 音声API（OpenAI Audio API互換）
        .route("/v1/audio/transcriptions", post(audio::transcriptions))
        .route("/v1/audio/speech", post(audio::speech))
        // 画像API（OpenAI Images API互換）
        .route("/v1/images/generations", post(images::generations))
        .route("/v1/images/edits", post(images::edits))
        .route("/v1/images/variations", post(images::variations));

    let api_key_protected_routes = api_key_routes.layer(middleware::from_fn_with_state(
        state.db_pool.clone(),
        crate::auth::middleware::api_key_auth_middleware,
    ));

    // `/v1/models*` は外部クライアント(APIキー)とノード(ノードトークン)の両方から参照される
    let models_routes = Router::new()
        .route("/v1/models", get(openai::list_models))
        .route("/v1/models/:model_id", get(openai::get_model));

    let models_protected_routes = models_routes.layer(middleware::from_fn_with_state(
        state.db_pool.clone(),
        crate::auth::middleware::api_key_or_node_token_auth_middleware,
    ));

    // NOTE: /v0/models (GET) は廃止されました。
    // モデル一覧は /v1/models を使用してください（Azure OpenAI 形式の capabilities 付き）。

    Router::new()
        // `/v0/*`: llm-router独自API（互換不要・versioned）
        .nest(
            "/v0",
            Router::new()
                // 認証エンドポイント（認証不要）
                .route("/auth/login", post(auth::login))
                .route("/auth/logout", post(auth::logout))
                // 保護されたルート
                .merge(protected_routes)
                .merge(node_protected_routes)
                // ノード管理
                .route("/nodes", post(nodes::register_node).get(nodes::list_nodes))
                .route("/nodes/:node_id", delete(nodes::delete_node))
                .route("/nodes/:node_id/disconnect", post(nodes::disconnect_node))
                .route("/nodes/:node_id/settings", put(nodes::update_node_settings))
                .route("/nodes/metrics", get(nodes::list_node_metrics))
                .route("/metrics/summary", get(nodes::metrics_summary))
                // ダッシュボードAPI
                .route("/dashboard/nodes", get(dashboard::get_nodes))
                .route("/dashboard/stats", get(dashboard::get_stats))
                .route(
                    "/dashboard/request-history",
                    get(dashboard::get_request_history),
                )
                .route("/dashboard/overview", get(dashboard::get_overview))
                .route(
                    "/dashboard/metrics/:node_id",
                    get(dashboard::get_node_metrics),
                )
                .route(
                    "/dashboard/request-responses",
                    get(dashboard::list_request_responses),
                )
                .route(
                    "/dashboard/request-responses/:id",
                    get(dashboard::get_request_response_detail),
                )
                .route(
                    "/dashboard/request-responses/export",
                    get(dashboard::export_request_responses),
                )
                .route("/dashboard/logs/router", get(logs::get_router_logs))
                // ノードログ取得（router→node proxy）
                .route("/nodes/:node_id/logs", get(logs::get_node_logs))
                // モデル管理API (SPEC-11106000 / SPEC-dcaeaec4)
                // NOTE: /models/available, /models/convert, /v0/models (GET) は廃止
                // モデル一覧は /v1/models を使用（Azure OpenAI 形式の capabilities 付き）
                .route("/models/register", post(models::register_model))
                .route("/models/*model_name", delete(models::delete_model))
                .route(
                    "/models/discover-gguf",
                    post(models::discover_gguf_endpoint),
                )
                // モデルファイル配信API (SPEC-48678000)
                .route("/models/blob/:model_name", get(models::get_model_blob))
                // Prometheus metrics（cloud prefix含む独自メトリクス）
                .route("/metrics/cloud", get(cloud_metrics::export_metrics)),
        )
        // OpenAI互換API
        .merge(api_key_protected_routes)
        .merge(models_protected_routes)
        .route("/dashboard", get(serve_dashboard_index))
        .route("/dashboard/", get(serve_dashboard_index))
        .route("/dashboard/*path", get(serve_dashboard_asset))
        // Playground UI (no legacy /chat path)
        .route("/playground", get(serve_playground_index))
        .route("/playground/", get(serve_playground_index))
        .route("/playground/*path", get(serve_playground_asset))
        .fallback(|| async { StatusCode::NOT_FOUND })
        .with_state(state)
}

async fn serve_dashboard_index() -> Response {
    embedded_dashboard_response(DASHBOARD_INDEX)
}

async fn serve_dashboard_asset(AxumPath(request_path): AxumPath<String>) -> Response {
    let normalized = normalize_dashboard_path(&request_path);
    match normalized {
        Some(path) => embedded_dashboard_response(&path),
        None => StatusCode::NOT_FOUND.into_response(),
    }
}

async fn serve_playground_index() -> Response {
    embedded_dashboard_response(PLAYGROUND_INDEX)
}

async fn serve_playground_asset(AxumPath(request_path): AxumPath<String>) -> Response {
    let normalized = normalize_playground_path(&request_path);
    match normalized {
        Some(path) => embedded_dashboard_response(&path),
        None => StatusCode::NOT_FOUND.into_response(),
    }
}

fn embedded_dashboard_response(path: &str) -> Response {
    match DASHBOARD_ASSETS.get_file(path) {
        Some(file) => file_response(file),
        None => StatusCode::NOT_FOUND.into_response(),
    }
}

fn file_response(file: &File<'_>) -> Response {
    let mime = MimeGuess::from_path(file.path())
        .first_or_octet_stream()
        .to_string();
    Response::builder()
        .status(StatusCode::OK)
        .header(header::CONTENT_TYPE, mime)
        .body(Body::from(file.contents().to_vec()))
        .expect("failed to build embedded dashboard response")
}

fn normalize_dashboard_path(request_path: &str) -> Option<String> {
    let trimmed = request_path.trim_matches('/');
    if trimmed.is_empty() {
        return Some(DASHBOARD_INDEX.to_string());
    }
    if trimmed.contains("..") || trimmed.contains('\\') {
        return None;
    }
    Some(trimmed.to_string())
}

fn normalize_playground_path(request_path: &str) -> Option<String> {
    let trimmed = request_path.trim_matches('/');
    if trimmed.is_empty() {
        return Some(PLAYGROUND_INDEX.to_string());
    }
    if trimmed.contains("..") || trimmed.contains('\\') {
        return None;
    }
    // Assets are shared with dashboard in the root assets/ directory
    Some(trimmed.to_string())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::{
        balancer::{LoadManager, MetricsUpdate},
        registry::NodeRegistry,
    };
    use axum::body::{to_bytes, Body};
    use axum::http::{Request, StatusCode};
    use llm_router_common::{protocol::RegisterRequest, types::GpuDeviceInfo};
    use tower::Service;

    async fn test_state() -> (AppState, NodeRegistry) {
        let registry = NodeRegistry::new();
        let load_manager = LoadManager::new(registry.clone());
        let request_history =
            std::sync::Arc::new(crate::db::request_history::RequestHistoryStorage::new().unwrap());
        let convert_manager = crate::convert::ConvertTaskManager::new(1);
        let db_pool = sqlx::SqlitePool::connect("sqlite::memory:")
            .await
            .expect("Failed to create test database");
        sqlx::migrate!("./migrations")
            .run(&db_pool)
            .await
            .expect("Failed to run migrations");
        let jwt_secret = "test-secret".to_string();
        let state = AppState {
            registry: registry.clone(),
            load_manager,
            request_history,
            convert_manager,
            db_pool,
            jwt_secret,
            http_client: reqwest::Client::new(),
        };
        (state, registry)
    }

    fn sample_gpu_devices() -> Vec<GpuDeviceInfo> {
        vec![GpuDeviceInfo {
            model: "Test GPU".to_string(),
            count: 1,
            memory: None,
        }]
    }

    #[tokio::test]
    async fn test_dashboard_static_served() {
        let (state, _) = test_state().await;
        let mut router = create_router(state);
        let response = router
            .call(
                Request::builder()
                    .method(axum::http::Method::GET)
                    .uri("/dashboard/index.html")
                    .body(Body::empty())
                    .unwrap(),
            )
            .await
            .unwrap();

        let status = response.status();
        let (parts, body) = response.into_parts();
        let bytes = to_bytes(body, 1024 * 1024).await.unwrap();

        assert_eq!(status, StatusCode::OK);
        let content_type = parts.headers[axum::http::header::CONTENT_TYPE]
            .to_str()
            .unwrap();
        assert!(content_type.starts_with("text/html"));
        assert!(bytes.starts_with(b"<!DOCTYPE html"));
    }

    #[tokio::test]
    async fn test_playground_static_served() {
        let (state, _) = test_state().await;
        let mut router = create_router(state);
        let response = router
            .call(
                Request::builder()
                    .method(axum::http::Method::GET)
                    .uri("/playground")
                    .body(Body::empty())
                    .unwrap(),
            )
            .await
            .unwrap();

        let status = response.status();
        let (parts, body) = response.into_parts();
        let bytes = to_bytes(body, 1024 * 1024).await.unwrap();

        assert_eq!(status, StatusCode::OK);
        let content_type = parts.headers[axum::http::header::CONTENT_TYPE]
            .to_str()
            .unwrap();
        assert!(content_type.starts_with("text/html"));
        assert!(bytes.starts_with(b"<!DOCTYPE html"));
    }

    #[tokio::test]
    async fn test_dashboard_nodes_endpoint_returns_json() {
        let (state, registry) = test_state().await;
        registry
            .register(RegisterRequest {
                machine_name: "test-node".into(),
                ip_address: "127.0.0.1".parse().unwrap(),
                runtime_version: "0.1.0".into(),
                runtime_port: 11434,
                gpu_available: true,
                gpu_devices: sample_gpu_devices(),
                gpu_count: Some(1),
                gpu_model: Some("Test GPU".to_string()),
                supported_runtimes: Vec::new(),
            })
            .await
            .unwrap();

        let mut router = create_router(state);
        let response = router
            .call(
                Request::builder()
                    .uri("/v0/dashboard/nodes")
                    .body(Body::empty())
                    .unwrap(),
            )
            .await
            .unwrap();

        assert_eq!(response.status(), StatusCode::OK);
        let bytes = to_bytes(response.into_body(), 1024 * 1024).await.unwrap();
        let nodes: serde_json::Value = serde_json::from_slice(&bytes).unwrap();
        assert!(nodes.is_array());
        assert_eq!(nodes.as_array().unwrap().len(), 1);
    }

    #[tokio::test]
    async fn test_dashboard_overview_endpoint_returns_all_sections() {
        let (state, registry) = test_state().await;
        registry
            .register(RegisterRequest {
                machine_name: "overview-node".into(),
                ip_address: "127.0.0.1".parse().unwrap(),
                runtime_version: "0.1.0".into(),
                runtime_port: 11434,
                gpu_available: true,
                gpu_devices: sample_gpu_devices(),
                gpu_count: Some(1),
                gpu_model: Some("Test GPU".to_string()),
                supported_runtimes: Vec::new(),
            })
            .await
            .unwrap();

        let mut router = create_router(state);
        let response = router
            .call(
                Request::builder()
                    .uri("/v0/dashboard/overview")
                    .body(Body::empty())
                    .unwrap(),
            )
            .await
            .unwrap();

        assert_eq!(response.status(), StatusCode::OK);
        let bytes = to_bytes(response.into_body(), 1024 * 1024).await.unwrap();
        let overview: serde_json::Value = serde_json::from_slice(&bytes).unwrap();
        assert!(overview["nodes"].is_array());
        assert!(overview["stats"].is_object());
        assert!(overview["history"].is_array());
        assert!(overview["generated_at"].is_string());
        assert!(overview["generation_time_ms"].as_u64().is_some());
    }

    #[tokio::test]
    async fn test_dashboard_metrics_endpoint_returns_history() {
        let (state, registry) = test_state().await;
        let node_id = registry
            .register(RegisterRequest {
                machine_name: "metrics-route".into(),
                ip_address: "127.0.0.1".parse().unwrap(),
                runtime_version: "0.1.0".into(),
                runtime_port: 11434,
                gpu_available: true,
                gpu_devices: sample_gpu_devices(),
                gpu_count: Some(1),
                gpu_model: Some("Test GPU".to_string()),
                supported_runtimes: Vec::new(),
            })
            .await
            .unwrap()
            .node_id;

        state
            .load_manager
            .record_metrics(MetricsUpdate {
                node_id,
                cpu_usage: 12.0,
                memory_usage: 34.0,
                gpu_usage: None,
                gpu_memory_usage: None,
                gpu_memory_total_mb: None,
                gpu_memory_used_mb: None,
                gpu_temperature: None,
                gpu_model_name: None,
                gpu_compute_capability: None,
                gpu_capability_score: None,
                active_requests: 1,
                average_response_time_ms: Some(90.0),
                initializing: false,
                ready_models: None,
            })
            .await
            .unwrap();

        let mut router = create_router(state);
        let response = router
            .call(
                Request::builder()
                    .uri(format!("/v0/dashboard/metrics/{node_id}"))
                    .body(Body::empty())
                    .unwrap(),
            )
            .await
            .unwrap();

        assert_eq!(response.status(), StatusCode::OK);
        let bytes = to_bytes(response.into_body(), 1024 * 1024).await.unwrap();
        let metrics: serde_json::Value = serde_json::from_slice(&bytes).unwrap();
        assert!(metrics.is_array());
        assert_eq!(metrics.as_array().unwrap().len(), 1);
        assert_eq!(
            metrics.as_array().unwrap()[0]["node_id"].as_str().unwrap(),
            node_id.to_string()
        );
    }
}
