# 機能仕様書: 音声モデル対応（TTS + ASR）

**機能ID**: `SPEC-26006000`
**作成日**: 2024-12-14
**ステータス**: 🔨 実装中（57/63タスク完了）
**入力**: ユーザー説明: "音声モデル対応（TTS + ASR）- llm-routerに音声モデル（TTS: Text-to-Speech、ASR: Speech-to-Text）対応を追加する。TTS用にONNX Runtime、ASR用にwhisper.cppを使用し、OpenAI API互換のエンドポイント（/v1/audio/speech, /v1/audio/transcriptions）を実装する。"

## ユーザーシナリオ＆テスト *(必須)*

### ユーザーストーリー1 - 音声認識（ASR）でテキスト変換 (優先度: P1)

ユーザーは音声ファイルをシステムにアップロードし、その音声内容をテキストに変換できる。これにより、会議の録音、インタビュー、ポッドキャストなどの音声コンテンツを文字起こしし、検索・編集・分析が可能になる。

**この優先度の理由**: 音声認識は多くのユースケース（議事録作成、字幕生成、音声検索）の基盤となる機能であり、ユーザーの生産性を大幅に向上させる。

**独立テスト**: 音声ファイルをアップロードし、正確なテキストが返却されることで完全にテスト可能。テキスト生成機能とは独立して価値を提供する。

**受け入れシナリオ**:

1. **前提** ユーザーが日本語の音声ファイル（WAV形式、30秒）を持っている、**実行** ファイルをアップロードし言語を指定、**結果** 日本語のテキストが返却される
2. **前提** ユーザーが英語の音声ファイル（MP3形式）を持っている、**実行** ファイルをアップロードし言語を自動検出に設定、**結果** 英語のテキストと検出言語が返却される
3. **前提** ユーザーが長時間の音声ファイル（10分以上）を持っている、**実行** ファイルをアップロード、**結果** タイムスタンプ付きの分割されたテキストが返却される

---

### ユーザーストーリー2 - 音声合成（TTS）でテキスト読み上げ (優先度: P1)

ユーザーはテキストを入力し、自然な音声ファイルを生成できる。これにより、音声コンテンツの作成、アクセシビリティ対応、音声ガイダンスなどが可能になる。

**この優先度の理由**: 音声合成はアクセシビリティ、コンテンツ制作、カスタマーサービスなど幅広い用途があり、ビジネス価値が高い。

**独立テスト**: テキストを入力し、再生可能な音声ファイルが返却されることで完全にテスト可能。

**受け入れシナリオ**:

1. **前提** ユーザーが日本語のテキスト（100文字）を持っている、**実行** テキストを送信し音声を生成、**結果** 自然な日本語音声ファイル（MP3形式）が返却される
2. **前提** ユーザーが英語のテキストを持っている、**実行** テキストと音声の種類（男性/女性）を指定して送信、**結果** 指定した音声タイプの音声ファイルが返却される
3. **前提** ユーザーがリアルタイムで音声を必要としている、**実行** テキストを送信しストリーミング出力を要求、**結果** 音声がストリーミングで返却され、生成完了を待たずに再生開始できる

---

### ユーザーストーリー3 - 複数ノードでの音声処理分散 (優先度: P2)

システム管理者は、音声処理を複数のノードに分散させ、高負荷時でも安定した応答を提供できる。これにより、大量の音声処理リクエストを効率的に処理できる。

**この優先度の理由**: 既存のテキスト生成と同様のロードバランシング機能を音声モデルにも適用することで、システムのスケーラビリティと信頼性を確保する。

**独立テスト**: 複数のノードを登録し、同時に複数の音声処理リクエストを送信して負荷分散されることで検証可能。

**受け入れシナリオ**:

1. **前提** 複数の音声処理対応ノードがシステムに登録されている、**実行** 多数の音声認識リクエストを同時送信、**結果** リクエストが複数ノードに分散処理される
2. **前提** 一部のノードがオフラインになっている、**実行** 音声処理リクエストを送信、**結果** オンラインのノードにのみリクエストがルーティングされる

---

### ユーザーストーリー4 - 音声モデルの登録と管理 (優先度: P2)

システム管理者は、使用したい音声モデルをシステムに登録し、管理できる。これにより、用途に応じた最適なモデルを選択して利用できる。

**この優先度の理由**: テキスト生成モデルと同様に、音声モデルも柔軟に追加・管理できることで、システムの拡張性を確保する。

**独立テスト**: 音声モデルを登録し、登録済みモデル一覧に表示されることで検証可能。

**受け入れシナリオ**:

1. **前提** 管理者がダッシュボードにログインしている、**実行** 音声認識モデルを登録、**結果** モデルがモデル一覧に表示され、利用可能になる
2. **前提** 複数の音声モデルが登録されている、**実行** 特定のモデルを指定してリクエスト、**結果** 指定したモデルで処理される

---

### エッジケース

- 対応していない音声フォーマットがアップロードされた場合、明確なエラーメッセージと対応フォーマット一覧が返却される
- 音声ファイルが破損している場合、適切なエラーメッセージが返却される
- 音声が無音の場合、空のテキストまたは適切なメッセージが返却される
- テキストが空または極端に長い場合、適切なエラーメッセージが返却される
- 音声モデルがノードにロードされていない場合、自動的にロードされるか、適切なエラーが返却される

## Clarifications

### Session 2025-12-23

- Q: 音声認識（ASR）で受け付ける音声ファイルの最大長は？ → A: 30分以内
- Q: 音声合成（TTS）でサポートすべき言語は？ → A: モデル依存（使用するTTSモデルがサポートする言語すべて）
- Q: 音声合成（TTS）で受け付けるテキストの最大文字数は？ → A: 5000文字以内
- Q: 音声合成（TTS）のデフォルト出力フォーマットと品質は？ → A: MP3 128kbps
- Q: 音声処理の同時リクエスト処理目標数は？ → A: 50件同時

---

## 要件 *(必須)*

### 機能要件

- **FR-001**: システムは音声ファイルをテキストに変換（音声認識）できる必要がある
- **FR-002**: システムはテキストを音声ファイルに変換（音声合成）できる必要がある
- **FR-003**: システムは複数の音声フォーマット（WAV, MP3, FLAC, OGG）をサポートする必要がある
- **FR-004**: システムは複数の言語での音声認識をサポートする必要がある
- **FR-005**: システムは音声認識で言語を自動検出できる必要がある
- **FR-006**: システムは複数の音声タイプ（voice）を提供し、ユーザーが選択できる必要がある
- **FR-007**: システムは音声処理リクエストを複数ノードに分散できる必要がある
- **FR-008**: システムは音声モデルの登録・削除・一覧表示ができる必要がある
- **FR-009**: システムは既存のテキスト生成APIとの互換性を維持する必要がある
- **FR-010**: システムは音声認識結果をタイムスタンプ付きで返却できる必要がある
- **FR-011**: システムは音声認識で最大30分までの音声ファイルを受け付ける必要がある
- **FR-012**: システムは音声合成で使用するTTSモデルがサポートするすべての言語に対応する必要がある
- **FR-013**: システムは音声合成で最大5000文字までのテキストを受け付ける必要がある
- **FR-014**: システムは音声合成のデフォルト出力をMP3 128kbpsで提供する必要がある

### 主要エンティティ

- **音声モデル（AudioModel）**: 音声処理を行うAIモデル。種類（ASR/TTS）、対応言語、対応フォーマットを持つ
- **音声認識リクエスト（TranscriptionRequest）**: 音声ファイル、使用モデル、言語設定を含む
- **音声合成リクエスト（SpeechRequest）**: テキスト、使用モデル、音声タイプ、出力フォーマットを含む
- **音声処理ノード（AudioNode）**: 音声モデルを実行できるノード。対応モデル種類を持つ

---

## スコープ外 *(オプション)*

以下の機能は本仕様のスコープ外とし、将来のバージョンで対応予定:

- リアルタイム音声ストリーミング入力（WebSocket経由）
- 話者分離（Speaker Diarization）
- 感情分析・トーン検出
- 音声のノイズ除去・品質向上
- カスタム音声の学習・クローニング

---

## 技術制約 *(該当する場合)*

- 音声認識はwhisper.cppがサポートするモデル形式に限定される
- 音声合成はONNX形式のモデルに限定される
- GPUメモリを共有する場合、テキスト生成と音声処理の同時実行に制限がある可能性がある

---

## 前提条件 *(該当する場合)*

この機能は以下を前提とします:

- ノードが音声処理に十分なメモリ（GPU/CPU）を持っている
- 音声モデルがHuggingFace等から入手可能である
- ネットワーク帯域が音声ファイル転送に十分である

---

## 依存関係 *(該当する場合)*

### 前提条件（このSPECが依存するもの）

- 既存モデル管理システム（登録・削除・一覧）✅ 実装済み
- 既存ノード管理システム（登録・ヘルスチェック・ロードバランシング）✅ 実装済み
- **SPEC-d4eb8796**: 認証・アクセス制御 ✅ 実装済み

### 依存元（このSPECに依存するもの）

- なし

---

## 成功基準 *(必須)*

以下の成功基準を満たす必要があります:

1. **音声認識精度**: 標準的な品質の音声ファイルで95%以上の文字認識精度を達成する
2. **音声認識速度**: 10秒の音声ファイルを5秒以内にテキスト変換できる
3. **音声合成速度**: 100文字のテキストを3秒以内に音声ファイルに変換できる
4. **音声合成品質**: 生成された音声が自然で聞き取りやすい（ユーザー評価で80%以上が「良い」以上）
5. **API互換性**: OpenAI Audio APIと互換性があり、既存のクライアントライブラリで利用できる
6. **システム安定性**: 音声処理機能の追加が既存のテキスト生成機能に影響を与えない
7. **スケーラビリティ**: 同時に50件の音声処理リクエストを処理できる
