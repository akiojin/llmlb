# 機能仕様書: Nemotron CUDA PoC

**機能ID**: `SPEC-55ebd062`
**作成日**: 2025-12-24
**ステータス**: ✅ 実装完了
**入力**: ユーザー説明: "Nemotron CUDA PoC: safetensorsから直接GPU（CUDA）で推論を実行するPoCを作成する。目的は、llama.cppに依存せずにsafetensors形式のNemotronモデルをCUDAで直接ロード・推論し、テキスト生成が成立することを検証すること。Metal対応は別途（本PoCはCUDA限定）。"

## Clarifications

### Session 2025-12-24

- Q: 対象とするNemotronモデルのサイズは？ → A: 複数サイズを段階的に検証（Mini→Medium）
- Q: PoCプログラムの配置場所は？ → A: `poc/nemotron-cuda-cpp/`（独立PoC）

## ユーザーシナリオ＆テスト *(必須)*

### ユーザーストーリー1 - safetensorsをCUDAで直接ロードしてテキスト生成したい (優先度: P1)

LLM runtimeの開発者として、Nemotronモデル（safetensors形式）をllama.cppに依存せずにCUDAで直接ロードし、テキスト生成が成立することを検証したい。これにより、safetensorsを正本としたGPU推論の実現可能性を確認できる。

**この優先度の理由**: llama.cpp（GGUF）に依存しない推論パスを確立することで、safetensorsを正本とするモデル管理方針を実現するための技術的基盤を検証する最重要項目。

**独立テスト**: Nemotronモデルのsafetensorsファイルをロードし、簡単なプロンプトに対して1トークン以上の生成が成功することで完全にテスト可能。

**受け入れシナリオ**:

1. **前提** CUDA対応GPU搭載マシンでPoCプログラムが起動可能、**実行** Nemotron safetensorsファイルを指定してロード、**結果** モデルがGPUメモリに正常にロードされる
2. **前提** モデルがGPUにロード済み、**実行** 「Hello」というプロンプトで推論を実行、**結果** 1トークン以上のテキストが生成される
3. **前提** モデルがGPUにロード済み、**実行** 複数トークンの生成を要求、**結果** 指定トークン数まで生成が継続する

---

### ユーザーストーリー2 - CUDAロードの失敗原因を明確にしたい (優先度: P2)

LLM runtimeの開発者として、モデルロードや推論が失敗した場合に、原因を特定できる情報が得られることを期待する。これにより、問題の切り分けと修正が効率的に行える。

**この優先度の理由**: PoCの目的は「できるかどうか」の検証であり、失敗時に原因が分からなければ検証として成立しない。

**独立テスト**: 意図的に不正なファイルや環境でPoCを実行し、エラーメッセージから原因が特定できることで独立してテスト可能。

**受け入れシナリオ**:

1. **前提** safetensorsファイルが存在しない、**実行** PoCプログラムを実行、**結果** 「ファイルが見つからない」旨のエラーメッセージが表示される
2. **前提** CUDA非対応環境でPoCを実行、**実行** モデルロードを試行、**結果** 「CUDAが利用できない」旨のエラーメッセージが表示される
3. **前提** GPUメモリが不足している、**実行** 大きなモデルのロードを試行、**結果** 「メモリ不足」旨のエラーメッセージが表示される

---

### ユーザーストーリー3 - 推論性能の基礎データを取得したい (優先度: P3)

LLM runtimeの開発者として、CUDA推論の基礎的な性能データ（ロード時間、トークン生成速度）を取得したい。これにより、本番実装に向けた性能目標の設定に役立てられる。

**この優先度の理由**: PoCの主目的は動作検証であり、性能測定は副次的な目標。ただし、実用性判断のための最低限のデータは必要。

**独立テスト**: 推論実行時にロード時間とトークン/秒が標準出力に表示されることで独立してテスト可能。

**受け入れシナリオ**:

1. **前提** モデルがロード可能、**実行** ロードを実行、**結果** ロード完了までの時間（秒）が表示される
2. **前提** 推論が実行可能、**実行** 100トークン生成、**結果** トークン/秒の速度が表示される

---

### エッジケース

- シャーディングされたsafetensors（複数ファイル）の場合、どう扱うか？→ index.jsonを読み込み、必要なシャードを順次ロードする
- GPUメモリに収まらない大きなモデルの場合、どう扱うか？→ 本PoCでは対象外（メモリに収まるモデルのみ対象）
- 推論中にGPUエラーが発生した場合、どう扱うか？→ エラーメッセージを出力してプログラムを終了する

## 要件 *(必須)*

### 機能要件

- **FR-001**: PoCプログラムはsafetensors形式のモデルファイルをCUDAデバイスにロードできる必要がある
- **FR-002**: PoCプログラムはシャーディングされたsafetensors（index.json + shards）を1つのモデルとして扱える必要がある
- **FR-003**: PoCプログラムはロードしたモデルでテキスト生成（1トークン以上）を実行できる必要がある
- **FR-004**: PoCプログラムはエラー発生時に原因を特定できるメッセージを出力する必要がある
- **FR-005**: PoCプログラムはロード時間とトークン生成速度を出力する必要がある
- **FR-006**: PoCプログラムはllama.cppに依存せずに動作する必要がある
- **FR-007**: PoCプログラムは`poc/nemotron-cuda-cpp/`ディレクトリに配置される必要がある
- **FR-008**: PoCプログラムはNemotron-Mini（4B程度）で初期検証し、成功後Nemotron-Medium（15B程度）に拡張する必要がある

### 主要エンティティ

- **safetensorsファイル**: Hugging Face形式のモデル重みファイル。単一ファイルまたはシャーディング（index.json + 複数shard）で構成される。
- **CUDAデバイス**: NVIDIA GPU。モデルの重みをロードし、推論演算を実行するハードウェア。
- **推論セッション**: モデルロード後、プロンプトを受け取りテキスト生成を行う実行単位。

---

## スコープ外 *(オプション)*

以下の機能は本仕様のスコープ外とし、将来のバージョンで対応予定:

- Metal（Apple Silicon）対応
- OpenAI互換APIとの統合
- ストリーミング出力
- KVキャッシュの最適化
- 量子化モデルのサポート
- マルチGPU対応
- llmlb Nodeへの統合

---

## 技術制約 *(該当する場合)*

- NVIDIA CUDA対応GPU（Compute Capability 7.0以上推奨）が必要
- CUDA Toolkit 12.x以上が必要
- 本PoCはLinux/Windowsを対象とし、macOSは対象外（Metal対応は別途）
- GPUメモリ要件: Nemotron-Mini（8GB以上）、Nemotron-Medium（24GB以上）

---

## 前提条件 *(該当する場合)*

この機能は以下を前提とします:

- SPEC-efff1da7（safetensors PoC）で確立したsafetensors読み込み手法を基盤とする
- SPEC-d7feaa2c（エンジン抽象化）のNemotronEngine検証結果を活用する
- 対象モデルはNemotronアーキテクチャ（Transformerベース）であること
- config.json、tokenizer.jsonが利用可能であること

---

## 依存関係 *(該当する場合)*

この機能は以下に依存します:

- SPEC-efff1da7（Nemotron safetensors PoC）: mmapロード手法
- SPEC-d7feaa2c（Nodeエンジンローダー抽象化）: NemotronEngine検証
- CUDA Toolkit / cuBLAS
- safetensors-cpp（ヘッダーオンリーライブラリ）

---

## 成功基準 *(必須)*

以下の成功基準を満たす必要があります:

1. Nemotronモデル（safetensors形式）がCUDA GPUにロードされ、1トークン以上のテキスト生成が成功する
2. ロード失敗時に、開発者が原因を特定できるエラーメッセージが表示される
3. llama.cppへの依存なしで推論が成立する
4. ロード時間とトークン生成速度が測定可能な形で出力される

---

## ⚡ クイックガイドライン

- ✅ ユーザーが「何を」必要とし「なぜ」必要なのかに焦点を当てる
- ❌ 「どのように」実装するかを避ける (技術スタック、API、コード構造なし)
- 👥 ビジネス関係者向けに記述 (開発者向けではない)
