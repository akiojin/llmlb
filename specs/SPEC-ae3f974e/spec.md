# 機能仕様書: 画像生成モデル対応（Image Generation）

**機能ID**: `SPEC-ae3f974e`
**作成日**: 2024-12-14
**ステータス**: 方針更新（要再設計）
**入力**: ユーザー説明: "画像生成モデル対応 - llmlbに画像生成モデル対応を追加する。OpenAI API互換のエンドポイント（/v1/images/generations, /v1/images/edits, /v1/images/variations）を実装する。"

## 決定事項（共有用サマリ）
- 画像生成は **safetensors正本** を前提に実行する
- stable-diffusion.cpp を当面利用し、safetensors を直接ロードできる前提とする
- safetensors/GGUF/Metal の選択は Node が実行環境に応じて行う（登録時の形式指定は行わない）
- Node実行時はPython依存を導入しない

## ユーザーシナリオ＆テスト *(必須)*

### ユーザーストーリー1 - テキストから画像生成（Text-to-Image） (優先度: P1)

ユーザーはテキストプロンプトを入力し、そのプロンプトに基づいた画像を生成できる。これにより、コンテンツ制作、デザインプロトタイピング、クリエイティブワークが可能になる。

**この優先度の理由**: 画像生成は最も基本的かつ需要の高い機能であり、ユーザーの創造性を大幅に向上させる。

**独立テスト**: テキストプロンプトを送信し、画像が返却されることで完全にテスト可能。

**受け入れシナリオ**:

1. **前提** ユーザーが英語のプロンプト（"A white cat sitting on a windowsill"）を持っている、**実行** プロンプトを送信、**結果** プロンプトに基づいた画像（URL or Base64）が返却される
2. **前提** ユーザーが複数の画像を必要としている、**実行** n=3を指定してプロンプトを送信、**結果** 3枚の異なる画像が返却される
3. **前提** ユーザーが特定のサイズの画像を必要としている、**実行** size="1024x1024"を指定して送信、**結果** 指定サイズの画像が返却される

---

### ユーザーストーリー2 - 画像編集（Inpainting） (優先度: P1)

ユーザーは既存の画像とマスクを提供し、指定した領域をプロンプトに基づいて編集できる。これにより、画像の一部を変更・修正・拡張できる。

**この優先度の理由**: 画像編集は既存の画像を活用する重要なユースケースであり、デザインワークフローに不可欠。

**独立テスト**: 画像、マスク、プロンプトを送信し、編集された画像が返却されることで検証可能。

**受け入れシナリオ**:

1. **前提** ユーザーが元画像とマスク画像を持っている、**実行** 画像、マスク、プロンプトを送信、**結果** マスク領域がプロンプトに基づいて編集された画像が返却される
2. **前提** ユーザーがマスクなしで編集したい、**実行** 画像とプロンプトのみを送信、**結果** 画像全体がプロンプトに基づいて変換される

---

### ユーザーストーリー3 - 画像バリエーション生成 (優先度: P2)

ユーザーは既存の画像を提供し、その画像に基づいたバリエーション（類似画像）を生成できる。これにより、デザインの探索や選択肢の拡大が可能になる。

**この優先度の理由**: バリエーション生成はクリエイティブワークの効率を向上させ、複数の選択肢を素早く生成できる。

**独立テスト**: 画像を送信し、バリエーション画像が返却されることで検証可能。

**受け入れシナリオ**:

1. **前提** ユーザーが元画像を持っている、**実行** 画像を送信、**結果** 元画像に似た新しい画像が返却される
2. **前提** ユーザーが複数のバリエーションを必要としている、**実行** n=3を指定して画像を送信、**結果** 3枚の異なるバリエーションが返却される

---

### ユーザーストーリー4 - 複数ノードでの画像処理分散 (優先度: P2)

システム管理者は、画像生成を複数のノードに分散させ、高負荷時でも安定した応答を提供できる。

**この優先度の理由**: 既存のテキスト・音声処理と同様のロードバランシング機能を画像モデルにも適用することで、システムのスケーラビリティと信頼性を確保する。

**独立テスト**: 複数のノードを登録し、同時に複数の画像生成リクエストを送信して負荷分散されることで検証可能。

**受け入れシナリオ**:

1. **前提** 複数の画像生成対応ノードがシステムに登録されている、**実行** 多数の画像生成リクエストを同時送信、**結果** リクエストが複数ノードに分散処理される
2. **前提** 一部のノードがオフラインになっている、**実行** 画像生成リクエストを送信、**結果** オンラインのノードにのみリクエストがルーティングされる

---

### エッジケース

- 対応していない画像フォーマットがアップロードされた場合、明確なエラーメッセージと対応フォーマット一覧が返却される
- 画像ファイルが4MBを超える場合、適切なエラーメッセージが返却される
- プロンプトが空の場合、適切なエラーメッセージが返却される
- 画像生成モデルがノードにロードされていない場合、自動的にロードされるか、適切なエラーが返却される
- 不適切なサイズ指定の場合、エラーまたは最も近い有効なサイズにフォールバックされる

## 要件 *(必須)*

### 機能要件

- **FR-001**: システムはテキストプロンプトから画像を生成できる必要がある
- **FR-002**: システムは画像とプロンプトから編集された画像を生成できる必要がある
- **FR-003**: システムは既存画像からバリエーションを生成できる必要がある
- **FR-004**: システムは複数の画像サイズ（256x256, 512x512, 1024x1024, 1792x1024, 1024x1792）をサポートする必要がある
- **FR-005**: システムは複数の画像品質（standard, hd）を提供できる必要がある
- **FR-006**: システムは複数のスタイル（vivid, natural）を提供できる必要がある
- **FR-007**: システムはURL形式またはBase64形式で画像を返却できる必要がある
- **FR-008**: システムは1リクエストで複数の画像（n: 1-10）を生成できる必要がある
- **FR-009**: システムは画像生成リクエストを複数ノードに分散できる必要がある
- **FR-010**: システムは既存のテキスト・音声APIとの互換性を維持する必要がある

### 主要エンティティ

- **画像生成モデル（ImageModel）**: 画像生成を行うAIモデル。対応サイズ、品質オプションを持つ
- **画像生成リクエスト（ImageGenerationRequest）**: プロンプト、使用モデル、サイズ、品質、スタイル、枚数を含む
- **画像編集リクエスト（ImageEditRequest）**: 元画像、マスク（オプション）、プロンプト、使用モデルを含む
- **画像バリエーションリクエスト（ImageVariationRequest）**: 元画像、使用モデル、サイズ、枚数を含む
- **画像処理ノード（ImageNode）**: 画像モデルを実行できるノード。RuntimeType::StableDiffusionを持つ

---

## スコープ外 *(オプション)*

以下の機能は本仕様のスコープ外とし、将来のバージョンで対応予定:

- ControlNet対応（ポーズ、エッジ、深度マップによる制御）
- Img2Img（画像から画像への変換、強度指定）
- アップスケーリング（超解像）
- ネガティブプロンプトの詳細制御
- LoRA/Textual Inversionの動的ロード
- プログレッシブ画像生成（段階的な画像表示）

---

## 技術制約 *(該当する場合)*

- 画像生成はsafetensorsを正本として直接読み込めるエンジンを使用する
- stable-diffusion.cpp は safetensors を直接ロードできる前提で継続利用する
- GGUFは利用可能な場合に Node が選択する（登録時の形式指定は行わない）
- safetensors/GGUF が共存する場合でも、形式指定は行わず Node が選択する
- GPUメモリを大量に消費する（SDXL: 8GB+）
- 1枚あたりの生成時間は数秒〜数十秒
- 入力画像のファイルサイズは最大4MBに制限される

---

## 前提条件 *(該当する場合)*

この機能は以下を前提とします:

- ノードが画像生成に十分なGPUメモリ（8GB+推奨）を持っている
- Stable Diffusionモデルが入手可能である（safetensors優先）
- ネットワーク帯域が画像ファイル転送に十分である

---

## 依存関係 *(該当する場合)*

この機能は以下に依存します:

- 既存のモデル管理システム（登録・削除・一覧）
- 既存のノード管理システム（登録・ヘルスチェック・ロードバランシング）
- 既存の認証・認可システム
- stable-diffusion.cpp（外部ライブラリ、safetensors直接ロード）

---

## Clarifications

### Session 2025-12-24

仕様を精査した結果、重大な曖昧さは検出されませんでした。

**確認済み事項**:

- 画像サイズ: 256x256, 512x512, 1024x1024, 1792x1024, 1024x1792（FR-004で明記）
- 入力画像サイズ制限: 最大4MB（技術制約で明記）
- 処理速度目標: 1024x1024画像を30秒以内（成功基準2で明記）
- 同時処理: 5件以上（成功基準5で明記）
- API互換性: OpenAI Images API互換（成功基準3で明記）
- 対応モデル形式: safetensors / GGUF（Nodeが選択）

**方針更新**:

- stable-diffusion.cpp は safetensors 直接読み込みの前提で運用する
- safetensors と GGUF が共存する場合でも format 指定は行わない

## 成功基準 *(必須)*

以下の成功基準を満たす必要があります:

1. **画像生成品質**: 生成された画像がプロンプトに適切に対応している（ユーザー評価で80%以上が「良い」以上）
2. **画像生成速度**: 1024x1024の画像を30秒以内に生成できる（GPU使用時）
3. **API互換性**: OpenAI Images APIと互換性があり、既存のクライアントライブラリで利用できる
4. **システム安定性**: 画像生成機能の追加が既存のテキスト・音声機能に影響を与えない
5. **スケーラビリティ**: 同時に5件以上の画像生成リクエストを処理できる（複数ノード使用時）
6. **エラーハンドリング**: 無効なリクエストに対して適切なエラーメッセージが返却される

## 実装状況

### Router側（Rust）- 完了

| ファイル | 状態 | 内容 |
|---------|------|------|
| `common/src/types.rs` | ✅ 完了 | RuntimeType::StableDiffusion, ModelType::ImageGeneration, ImageSize, ImageQuality, ImageStyle, ImageResponseFormat追加 |
| `common/src/protocol.rs` | ✅ 完了 | ImageGenerationRequest, ImageEditRequest, ImageVariationRequest, ImageResponse, ImageData追加 |
| `router/src/api/images.rs` | ✅ 完了 | generations, edits, variationsエンドポイント |
| `router/src/api/mod.rs` | ✅ 完了 | imagesモジュール追加、ルート登録 |
| `router/tests/contract/images_*.rs` | ✅ 完了 | 契約テスト（TDD RED Phase） |
| `router/tests/integration/images_api_test.rs` | ✅ 完了 | 統合テスト（TDD RED Phase） |

### Node側（C++）- 完了

| ファイル | 状態 | 内容 |
|---------|------|------|
| `node/CMakeLists.txt` | ✅ 完了 | BUILD_WITH_SDオプション、stable-diffusion.cppリンク |
| `node/include/core/sd_manager.h` | ✅ 完了 | Stable Diffusionマネージャーヘッダー |
| `node/src/core/sd_manager.cpp` | ✅ 完了 | stable-diffusion.cpp統合実装 |
| `node/include/api/image_endpoints.h` | ✅ 完了 | 画像エンドポイントヘッダー |
| `node/src/api/image_endpoints.cpp` | ✅ 完了 | 画像エンドポイント実装 |
| `node/src/main.cpp` | ✅ 完了 | SDManager・ImageEndpoints登録 |
