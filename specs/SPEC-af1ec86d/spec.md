# 機能仕様書: LM Studioエンドポイントタイプの検出・分類・メタデータ取得

**機能ID**: `SPEC-af1ec86d`
**作成日**: 2026-02-13
**ステータス**: 実装中
**入力**: ユーザー説明: "LM Studioエンドポイントタイプの検出・分類・メタデータ取得機能。llmlbは現在xLLM、Ollama、vLLM、OpenAI互換の4つのエンドポイントタイプを自動検出している。LM Studioは人気のローカルLLMサーバーだが、現状ではopenai_compatibleに分類される。LM Studioを独立タイプとして判別し、固有API（/api/v1/models等）を活用した機能連携を実現する。"

## ユーザーシナリオ＆テスト

### ユーザーストーリー1 - LM Studioエンドポイントの自動識別 (優先度: P1)

管理者として、LM Studioサーバーを登録した際に、
システムが自動的にLM Studioであることを識別してほしい。
これにより、手動でのタイプ指定なしに適切な管理と表示が行われる。

**この優先度の理由**: エンドポイントタイプの自動識別は
すべての後続機能（メタデータ取得、フィルタリング、将来の機能連携）の前提条件である。
現状LM Studioがopenai_compatibleとして誤分類される問題の根本解決となる。

**独立テスト**: LM StudioサーバーのURLを登録し、
エンドポイント一覧でタイプが「lm_studio」と表示されることを確認することで、
独立して価値を提供する。

**受け入れシナリオ**:

1. **前提** LM Studioサーバーが稼働中、**実行** エンドポイント登録APIにLM StudioのURLを送信、**結果** タイプが「lm_studio」として自動検出される
2. **前提** LM Studioサーバーが稼働中、**実行** ダッシュボードからLM StudioのURLを登録、**結果** エンドポイント一覧に「lm_studio」タイプで表示される
3. **前提** 検出済みのLM Studioエンドポイントが存在、**実行** エンドポイント詳細を取得、**結果** endpoint_type_sourceが「auto」、endpoint_type_reasonに検出根拠が含まれる
4. **前提** LM Studioエンドポイントが一時オフライン後に復旧、**実行** ヘルスチェックが成功、**結果** タイプがlm_studioとして再検出される

---

### ユーザーストーリー2 - LM Studioモデルの詳細メタデータ表示 (優先度: P1)

管理者として、LM Studioに登録されたモデルの詳細情報
（アーキテクチャ、量子化タイプ、ファイルサイズ、コンテキスト長、
フォーマット、対応機能等）を確認したい。
これにより、モデルの特性を把握し、適切な運用判断ができる。

**この優先度の理由**: メタデータの取得はモデル同期時のmax_tokens設定に直結し、
推論リクエストのルーティング精度に影響する。LM Studio固有APIから豊富な情報が
取得可能であり、既存のxLLM/Ollamaと同等以上の情報が得られる。

**独立テスト**: LM Studioエンドポイントを登録し、
モデル同期後にモデル一覧でメタデータ（コンテキスト長、量子化、アーキテクチャ等）
が表示されることを確認する。

**受け入れシナリオ**:

1. **前提** LM Studioエンドポイントが登録済み、**実行** モデル同期が実行される、**結果** 各モデルのmax_context_lengthがメタデータとして保存される
2. **前提** LM Studioにモデルがロード済み、**実行** モデル一覧を取得、**結果** アーキテクチャ（llama, mistral等）、量子化タイプ、パラメータサイズが表示される
3. **前提** LM Studioに複数フォーマット（GGUF/MLX）のモデルが存在、**実行** モデル一覧を取得、**結果** 各モデルのフォーマット情報が正しく表示される
4. **前提** LM Studioにビジョン対応モデルが存在、**実行** モデルメタデータを取得、**結果** ビジョン対応やツール利用対応などのcapabilities情報が含まれる

---

### ユーザーストーリー3 - LM Studioタイプによるフィルタリングと手動指定 (優先度: P2)

管理者として、エンドポイント一覧をLM Studioタイプでフィルタリングしたい。
また、自動検出が困難な環境（特殊なネットワーク構成等）では
手動でLM Studioタイプを指定できるようにしたい。

**この優先度の理由**: 複数のエンドポイントタイプが混在する環境では、
タイプ別のフィルタリングが運用効率に直結する。手動指定は
自動検出のフォールバックとして必要。

**独立テスト**: 複数タイプのエンドポイントが登録された状態で、
`?type=lm_studio` でフィルタし、LM Studioエンドポイントのみが
返されることを確認する。

**受け入れシナリオ**:

1. **前提** LM Studio・Ollama・vLLMのエンドポイントが登録済み、**実行** `GET /api/endpoints?type=lm_studio` を実行、**結果** LM Studioエンドポイントのみが返される
2. **前提** 管理者がAPIを利用、**実行** `endpoint_type: "lm_studio"` を手動指定してエンドポイントを登録、**結果** 自動検出をスキップし、lm_studioタイプとして登録される
3. **前提** 手動指定でlm_studioタイプが設定済み、**実行** エンドポイント詳細を取得、**結果** endpoint_type_sourceが「manual」と表示される

---

### ユーザーストーリー4 - 他タイプとの誤検出防止 (優先度: P2)

管理者として、LM Studio以外のエンドポイント（vLLM、Ollama、xLLM、
汎用OpenAI互換API）がLM Studioと誤検出されないことを保証したい。
また、LM Studioが他のタイプとして誤検出されないことも保証したい。

**この優先度の理由**: 誤検出はメタデータ取得の失敗や不適切な機能連携を
引き起こし、システムの信頼性を損なう。

**独立テスト**: 各タイプのエンドポイントを登録し、
すべてが正しいタイプとして検出されることを確認する。

**受け入れシナリオ**:

1. **前提** vLLMサーバーが稼働中、**実行** エンドポイント登録、**結果** vLLMとして検出され、lm_studioにはならない
2. **前提** Ollamaサーバーが稼働中、**実行** エンドポイント登録、**結果** Ollamaとして検出される
3. **前提** 汎用OpenAI互換APIサーバーが稼働中、**実行** エンドポイント登録、**結果** openai_compatibleとして検出される
4. **前提** LM Studioサーバーが稼働中、**実行** エンドポイント登録、**結果** lm_studioとして検出され、openai_compatibleにはならない

---

### エッジケース

- LM Studioサーバーが起動直後でモデル未ロードの場合、検出はどうなるか？
  → 固有APIパス（/api/v1/models）のレスポンス形式で判定するため、
  モデル有無に関わらず検出可能
- LM Studioの固有APIエンドポイントがレスポンスを返さない（タイムアウト等）場合は？
  → フォールバック判定（Serverヘッダー、owned_by）に移行する
- LM Studio 0.4.0未満の旧バージョンの場合は？
  → 固有APIが存在しない場合はフォールバック判定を試み、
  それでも検出できなければopenai_compatibleとして分類される（意図的）
- エンドポイントのベースURLが非標準ポート（1234以外）の場合は？
  → ポートに依存せず、APIレスポンスの内容で判定するため影響なし

## Clarifications

### Session 2026-02-13

- Q: ModelMetadata新フィールド（format, capabilities等）はLM Studio専用か全タイプ共通か？ → A: 全タイプ共通フィールドとして追加し、各タイプで取得可能な範囲で値を返す
- Q: capabilities情報のAPI表現形式は？ → A: フラットなOptionalブールフィールド（例: supports_vision, supports_tool_use）として表現する

## 要件

### 機能要件

- **FR-001**: システムはLM Studioを独立したエンドポイントタイプ（lm_studio）として認識する必要がある
- **FR-002**: システムはエンドポイント登録時にLM Studioを自動検出する必要がある
- **FR-003**: 自動検出は複合判定方式で行う必要がある（固有APIパス → Serverヘッダー → owned_byフィールド）
- **FR-004**: 検出順序はxLLM → Ollama → LM Studio → vLLM → OpenAI互換 → Unknownの順である必要がある
- **FR-005**: システムはLM Studio固有API（/api/v1/models）からモデルメタデータを取得する必要がある
- **FR-006**: 取得するメタデータにはアーキテクチャ、ファイルサイズ、パラメータサイズ、コンテキスト長、フォーマット、量子化情報（名前・ビット数）を含む必要がある。対応機能（vision、tool_use等）はフラットなOptionalブールフィールド（supports_vision, supports_tool_use）として表現する
- **FR-007**: 既存のモデルメタデータ構造を拡張し、新フィールド（format, capabilities等）は全エンドポイントタイプ共通とする。各タイプは取得可能な範囲で値を返し、未対応フィールドはnullとする
- **FR-008**: LM Studioエンドポイントはメタデータ取得対応タイプとして扱う必要がある
- **FR-009**: LM Studioエンドポイントはモデルダウンロード非対応タイプとして扱う必要がある（将来対応予定）
- **FR-010**: エンドポイント一覧APIでlm_studioタイプによるフィルタリングが可能である必要がある
- **FR-011**: エンドポイント登録時にendpoint_type: "lm_studio" を手動指定できる必要がある
- **FR-012**: タイプが未確定（Unknown）のLM Studioエンドポイントはヘルスチェック成功時に再検出される必要がある
- **FR-013**: LM Studio以外のエンドポイントタイプがlm_studioとして誤検出されないことを保証する必要がある
- **FR-014**: 対象バージョンはLM Studio最新安定版（0.4.0以降）のみとする
- **FR-015**: 接続方式は直接接続を前提とする（プロキシ経由は手動タイプ指定で対応）

### 主要エンティティ

- **EndpointType**: エンドポイントの種別を表す分類。LmStudioが新たに追加される。既存のXllm、Ollama、Vllm、OpenaiCompatible、Unknownと同列
- **ModelMetadata**: モデルの詳細情報。LM Studio固有の情報（フォーマット、対応機能等）を格納できるよう拡張される

## 成功基準

### 測定可能な結果

- **SC-001**: LM Studioサーバー（0.4.0以降）がlm_studioタイプとして100%自動検出される
- **SC-002**: 既存タイプ（xLLM、Ollama、vLLM、OpenAI互換）の検出精度が変化しない（回帰なし）
- **SC-003**: LM Studioエンドポイントからmax_context_lengthを含むメタデータが取得され、モデル同期に反映される
- **SC-004**: エンドポイント一覧のlm_studioフィルタが正しく機能する
- **SC-005**: 全既存テストが変更なしで通過し、新規テストが追加される
