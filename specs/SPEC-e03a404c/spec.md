# 機能仕様書: 画像認識モデル対応（Image Understanding）

**機能ID**: `SPEC-e03a404c`
**作成日**: 2025-12-24
**ステータス**: 実装待ち
**入力**: ユーザー説明: "画像認識モデル対応（Image Understanding）- llm-routerにVisionモデル対応を追加し、画像を含むチャットリクエストを処理できるようにする。OpenAI Vision API互換のエンドポイント（/v1/chat/completions with images）を実装する。"

## 決定事項（共有用サマリ）
- 画像認識は **safetensors正本** を前提に実行する
- GGUFは **safetensorsが存在しない場合のみ** フォールバックとして許可する
- Node実行時はPython依存を導入しない

## ユーザーシナリオ＆テスト *(必須)*

### ユーザーストーリー1 - 画像を含むチャットリクエストを送信する (優先度: P1)

開発者として、画像URLまたはBase64エンコードされた画像を含むチャットリクエストを送信し、モデルが画像の内容を理解した上で回答を得たい。これにより、画像に関する質問応答、画像の説明生成、OCRなどのタスクが可能になる。

**この優先度の理由**: 画像認識は多くのユースケース（ドキュメント分析、画像キャプション、視覚的QA）の基盤となる機能であり、マルチモーダルAIの中核となる。

**独立テスト**: 画像を含むchat completionsリクエストを送信し、画像の内容を反映したテキストレスポンスが返却されることを確認することで完全にテスト可能。

**受け入れシナリオ**:

1. **前提** LLaVA等のVisionモデルがルーターに登録されている、**実行** 画像URL付きのchat completionsリクエストを送信、**結果** 画像の内容を説明するテキストが返却される
2. **前提** Visionモデルがルーターに登録されている、**実行** Base64エンコードされた画像付きのリクエストを送信、**結果** 画像の内容を理解した回答が返却される
3. **前提** Visionモデルがルーターに登録されている、**実行** 複数の画像を含むリクエストを送信、**結果** すべての画像を考慮した回答が返却される

---

### ユーザーストーリー2 - 非対応モデルでのエラーハンドリング (優先度: P1)

開発者として、Vision機能に対応していないモデル（例: 純粋なテキストLLM）を指定して画像付きリクエストを送信した場合、明確なエラーメッセージを受け取りたい。これにより、間違ったモデルを使用していることにすぐ気づき、正しいモデルに変更できる。

**この優先度の理由**: ユーザーが間違ったモデルを使用した場合に、黙って失敗したり不正な結果を返したりするのではなく、即座に明確なフィードバックを提供することが重要。

**独立テスト**: 画像付きリクエストを非対応モデルに送信し、エラーレスポンスが返ることを確認することで完全にテスト可能。

**受け入れシナリオ**:

1. **前提** LLaMA（テキストのみ対応）がルーターに登録されている、**実行** 画像付きのchat completionsリクエストを送信、**結果** エラーレスポンス「Model 'llama-3.1-8b' does not support image understanding」が返る
2. **前提** Vision非対応モデルを指定、**実行** 画像URLを含むリクエストを送信、**結果** 400 Bad Requestとエラーメッセージが返る

---

### ユーザーストーリー3 - ストリーミングレスポンス (優先度: P2)

開発者として、画像認識リクエストに対してストリーミングレスポンスを受け取りたい。これにより、長い説明文の生成中でもリアルタイムで結果を表示できる。

**この優先度の理由**: ユーザー体験の向上に重要だが、基本機能の後に実装可能。

**独立テスト**: stream=trueで画像付きリクエストを送信し、SSEイベントが順次返却されることを確認。

**受け入れシナリオ**:

1. **前提** Visionモデルが登録されている、**実行** `stream: true`で画像付きリクエストを送信、**結果** Server-Sent Eventsで回答がストリーミング配信される

---

### ユーザーストーリー4 - モデル一覧でVision capabilityを確認する (優先度: P2)

開発者として、各モデルがVision機能に対応しているかをモデル一覧で確認したい。これにより、適切なモデルを選択できる。

**この優先度の理由**: エラーを事前に防ぐための情報提供であり、開発体験を向上させる。

**独立テスト**: `/v1/models` を呼び出し、各モデルに `image_understanding` capabilityが含まれていることを確認。

**受け入れシナリオ**:

1. **前提** 複数のモデルがルーターに登録されている、**実行** `/v1/models` を呼び出す、**結果** 各モデルの `capabilities.image_understanding` が正しく表示される

---

### エッジケース

- 画像URLがアクセス不能な場合、適切なエラーメッセージが返される
- Base64エンコードが不正な場合、明確なエラーメッセージが返される
- 画像サイズが大きすぎる場合（例: 20MB超）、エラーまたは自動リサイズされる
- サポートされていない画像形式（例: TIFF）の場合、対応形式一覧付きエラーが返される
- 複数画像の合計サイズが制限を超える場合、適切なエラーが返される

---

## 要件 *(必須)*

### 機能要件

- **FR-001**: システムは、画像URL付きのchat completionsリクエストを処理できる必要がある
- **FR-002**: システムは、Base64エンコードされた画像付きのリクエストを処理できる必要がある
- **FR-003**: システムは、複数画像を含むリクエストを処理できる必要がある
- **FR-004**: システムは、Vision非対応モデルへの画像付きリクエストを400エラーで拒否する必要がある
- **FR-005**: システムは、画像付きリクエストのストリーミングレスポンスをサポートする必要がある
- **FR-006**: システムは、`/v1/models` レスポンスに `image_understanding` capabilityを含める必要がある
- **FR-007**: システムは、JPEG, PNG, GIF, WebP形式の画像をサポートする必要がある
- **FR-008**: システムは、最大10MBまでの画像を受け付ける必要がある
- **FR-009**: システムは、1リクエストあたり最大10枚の画像を受け付ける必要がある

### 主要エンティティ

- **ImageContent**: 画像データを表す。URLまたはBase64形式、MIME type、サイズ情報を持つ
- **VisionCapability**: モデルのVision対応状況を表す。対応画像形式、最大画像数などを持つ

---

## スコープ外 *(オプション)*

以下の機能は本仕様のスコープ外とし、将来のバージョンで対応予定:

- 動画の処理・分析
- リアルタイムカメラ入力
- 画像内のオブジェクト検出（バウンディングボックス出力）
- 画像のセグメンテーション
- カスタムVisionモデルの学習・ファインチューニング

---

## 技術制約 *(該当する場合)*

- Visionモデルはsafetensorsを直接読み込める新エンジンが必要
- GGUFはsafetensorsが存在しない場合のみフォールバックとして許可する
- 画像処理に追加のGPUメモリが必要（モデルにより2-8GB追加）
- Base64デコードはルーター側で実行し、ノードには生データを送信

---

## 前提条件 *(該当する場合)*

この機能は以下を前提とします:

- ノードがVisionモデルをロード可能なエンジンを持っている
- モデルがマルチモーダル入力に対応している（LLaVA、Qwen-VL等）
- 十分なGPUメモリ（Vision処理用）が確保されている

---

## 依存関係 *(該当する場合)*

### 前提条件（このSPECが依存するもの）

- **SPEC-47649000**: モデルメタデータSQLite統合 ✅ 実装済み
- **SPEC-63acef08**: 統一APIプロキシ ✅ 実装済み
- **SPEC-32637000**: モデルcapabilities検証 ✅ 実装済み

### 依存元（このSPECに依存するもの）

- なし

---

## Clarifications

### Session 2025-12-24

仕様を精査した結果、重大な曖昧さは検出されませんでした。

**確認済み事項**:

- 画像フォーマット: JPEG, PNG, GIF, WebP（FR-007で明記）
- サイズ制限: 最大10MB/画像、最大10枚/リクエスト（FR-008, FR-009で明記）
- 処理速度目標: 1024x1024画像を5秒以内（成功基準2で明記）
- エラーハンドリング: 非対応モデルへは400エラー（FR-004で明記）
- API互換性: OpenAI Vision API互換（成功基準3で明記）

**実装時の判断に委ねる事項**:

- 画像URL取得時のタイムアウト値（推奨: 30秒）
- 画像URL取得時のリダイレクト追従の深さ（推奨: 最大3回）
- Base64デコードエラー時の詳細メッセージ形式

**方針更新**:

- safetensors正本を前提に再設計する
- GGUFはsafetensorsが存在しない場合のみフォールバック

---

## 成功基準 *(必須)*

以下の成功基準を満たす必要があります:

1. **画像認識精度**: 標準的なベンチマーク画像で妥当な説明を生成できる
2. **処理速度**: 1枚の標準画像（1024x1024）の処理が5秒以内に完了する
3. **API互換性**: OpenAI Vision APIと互換性があり、既存のクライアントライブラリで利用できる
4. **エラー処理**: 非対応モデルへのリクエストは100%エラーとして処理される
5. **システム安定性**: 画像認識機能の追加が既存のテキスト生成機能に影響を与えない
