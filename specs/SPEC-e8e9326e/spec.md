# 機能仕様書: ロードバランサー主導エンドポイント登録システム

**機能ID**: `SPEC-e8e9326e`
**作成日**: 2026-01-14
**ステータス**: 追加実装中
**入力**: ユーザー説明: "ロードバランサー主導エンドポイント登録システム - ロードバランサーがダッシュボードおよびREST API経由でOpenAI互換APIエンドポイント（xLLM、Ollama、vLLM等）を登録・管理する。既存のノード自己登録システム（SPEC-94621a1f）を廃止し、統一されたエンドポイント管理に移行する。プル型ヘルスチェック（GET /v1/models）でエンドポイントの稼働状況を監視し、モデル一覧の自動同期機能を提供する。"

## スコープ（llmlb側）

- llmlbはエンドポイントタイプの自動判別（xLLM検出）とAPIルーティングに専念する。
- xLLMのモデル実装・運用詳細はxLLMリポジトリ（SPEC-48678000/SPEC-93536000）に移管済み。


## ユーザーシナリオ＆テスト

### ユーザーストーリー1 - エンドポイントの登録 (優先度: P1)

管理者として、ダッシュボードまたはAPIからOpenAI互換APIエンドポイントを登録したい。
これにより、xLLM（自社推論サーバー）、Ollama、vLLM等を統一的に管理できるようになる。
すべてのエンドポイントはOpenAI互換APIとして扱われる。

**この優先度の理由**: エンドポイント登録はシステムの中核機能であり、
他のすべての機能（ヘルスチェック、モデル同期、ルーティング）の前提条件となる。

**独立テスト**: ダッシュボードからエンドポイントを登録し、
エンドポイント一覧に表示されることを確認することで、独立して価値を提供する。

**受け入れシナリオ**:

1. **前提** 管理者がダッシュボードにログイン済み、**実行** 新規エンドポイント登録フォームにxLLMサーバーのURLを入力して保存、**結果** エンドポイントが一覧に追加される
2. **前提** 管理者がダッシュボードにログイン済み、**実行** Ollamaサーバーのエンドポイントを登録、**結果** エンドポイントが一覧に追加される
3. **前提** APIキーを持つ管理者、**実行** REST APIでエンドポイントを登録、**結果** 201 Createdが返り、エンドポイントが作成される
4. **前提** 同じURLのエンドポイントが既に存在、**実行** 同じURLで新規登録を試行、**結果** 重複エラーが返され、登録は拒否される

---

### ユーザーストーリー2 - エンドポイントの稼働状況監視 (優先度: P1)

管理者として、登録したエンドポイントの稼働状況をリアルタイムで確認したい。
ロードバランサーが定期的にエンドポイントをチェックし、オンライン/オフライン状態を
自動的に更新することで、障害を迅速に検知できる。

**この優先度の理由**: 稼働状況の監視がなければ、障害ノードにリクエストが
振り分けられ、ユーザー体験が損なわれる。安定運用の基盤となる機能。

**独立テスト**: エンドポイントを登録し、稼働状況がダッシュボードに
表示されること、エンドポイント停止時にオフライン状態に遷移することを確認する。

**受け入れシナリオ**:

1. **前提** エンドポイントが登録されている、**実行** ダッシュボードでエンドポイント一覧を表示、**結果** 各エンドポイントの稼働状況（オンライン/オフライン）が表示される
2. **前提** オンラインのエンドポイントがある、**実行** そのエンドポイントのサービスを停止、**結果** 60秒以内にロードバランサーが検知し、状態がオフラインに変わる
3. **前提** オフラインのエンドポイントがある、**実行** そのエンドポイントのサービスを再起動、**結果** 次回のヘルスチェックで検知され、状態がオンラインに復帰する
4. **前提** pending / online / offline / error の状態を持つエンドポイントが存在する、**実行** 一覧・詳細・Playgroundでステータス表示を確認、**結果** ステータスバッジの色分けが一貫している（online=緑、pending=黄、offline=赤系淡色、error=赤）

---

### ユーザーストーリー3 - モデル一覧の自動同期 (優先度: P2)

管理者として、エンドポイントで利用可能なモデルを自動的に取得したい。
手動でモデルを登録する手間を省き、エンドポイント側のモデル追加・削除が
ロードバランサーに自動反映されるようにしたい。

**この優先度の理由**: モデル同期により運用負荷が大幅に軽減される。
ただし、手動でのモデル指定でも最低限の運用は可能なため、P2とする。

**独立テスト**: エンドポイントを登録後、モデル同期を実行し、
そのエンドポイントで利用可能なモデルがロードバランサーに表示されることを確認する。

**受け入れシナリオ**:

1. **前提** Ollamaエンドポイントが登録されている、**実行** モデル同期を実行、**結果** Ollamaにロードされているモデルがロードバランサーのモデル一覧に表示される
2. **前提** xLLMエンドポイントが登録されている、**実行** モデル同期を実行、**結果** xLLMで利用可能なモデルがロードバランサーのモデル一覧に表示される
3. **前提** エンドポイントにモデルが追加された、**実行** 次回のモデル同期、**結果** 新しいモデルがロードバランサーに反映される
4. **前提** エンドポイントの`/v1/models`が一時的にエラーとなる、**実行** 次回以降のモデル同期、**結果** エラーが解消したタイミングでモデル一覧が自動的に追随し、失敗だけで長時間更新が止まらない

---

### ユーザーストーリー4 - エンドポイントの接続テスト (優先度: P2)

管理者として、エンドポイント登録前に接続テストを実行したい。
URLやAPIキーの設定ミスを事前に検出し、登録後のトラブルを防止したい。

**この優先度の理由**: 接続テストにより設定ミスを早期発見できる。
ただし、テストなしでも登録自体は可能なため、P2とする。

**独立テスト**: 接続テストボタンを押し、成功/失敗の結果が
表示されることを確認する。

**受け入れシナリオ**:

1. **前提** 正しいURLを入力済み、**実行** 接続テストを実行、**結果** 成功メッセージとエンドポイント情報が表示される
2. **前提** 不正なURLを入力済み、**実行** 接続テストを実行、**結果** 失敗メッセージと具体的なエラー理由が表示される
3. **前提** APIキーが必要なエンドポイントで誤ったキーを入力、**実行** 接続テストを実行、**結果** 認証エラーが表示される

---

### ユーザーストーリー5 - エンドポイントの管理操作 (優先度: P3)

管理者として、登録済みエンドポイントの編集・削除を行いたい。
URLの変更、メモの追加、不要になったエンドポイントの削除ができるようにしたい。

**この優先度の理由**: 日常的な管理操作として必要だが、
初期登録とヘルスチェックが動作すれば基本的な運用は可能なため、P3とする。

**独立テスト**: エンドポイントの編集・削除操作を行い、
変更が反映されることを確認する。

**受け入れシナリオ**:

1. **前提** エンドポイントが登録されている、**実行** エンドポイントの名前を編集して保存、**結果** 新しい名前で表示される
2. **前提** エンドポイントが登録されている、**実行** エンドポイントを削除、**結果** エンドポイントが一覧から削除される
3. **前提** エンドポイントにメモを追加、**実行** エンドポイント詳細を表示、**結果** メモが表示される

---

### ユーザーストーリー6 - エンドポイントタイプの自動判別 (優先度: P1)

運用者として、エンドポイントを登録する際に、そのエンドポイントがxLLM、Ollama、vLLM、またはその他のOpenAI互換APIのいずれであるかを自動的に判別してほしい。これにより、手動でタイプを指定する手間を省き、誤設定を防止できる。

**この優先度の理由**: エンドポイントタイプの判別は、後続の機能フィルタリングやxLLM固有機能（モデルダウンロード等）の基盤となるため、最も重要。

**独立テスト**: 各種タイプのエンドポイントを登録し、正しいタイプが自動判別されることを確認することで完全にテストでき、タイプ情報の信頼性を提供する。

**受け入れシナリオ**:

1. **前提** xLLMサーバーが稼働している、**実行** そのURLでエンドポイントを登録する、**結果** タイプが「xLLM」として判別・保存される
2. **前提** Ollamaサーバーが稼働している、**実行** そのURLでエンドポイントを登録する、**結果** タイプが「Ollama」として判別・保存される
3. **前提** vLLMサーバーが稼働している、**実行** そのURLでエンドポイントを登録する、**結果** タイプが「vLLM」として判別・保存される
4. **前提** その他のOpenAI互換APIサーバーが稼働している、**実行** そのURLでエンドポイントを登録する、**結果** タイプが「OpenAI互換」として判別・保存される

---

### ユーザーストーリー7 - タイプに基づく機能フィルタリング (優先度: P1)

開発者として、特定のタイプのエンドポイントのみを対象に操作を行いたい。例えば、xLLMのみが対応する機能（モデルダウンロード等）を使用する際に、xLLMタイプのエンドポイントだけをフィルタリングしたい。

**この優先度の理由**: タイプ判別の主要な用途であり、xLLM固有機能の制御に必須。

**独立テスト**: 複数タイプのエンドポイントが登録された状態で、特定タイプでフィルタリングして正しいエンドポイントのみが返されることを確認する。

**受け入れシナリオ**:

1. **前提** xLLM、Ollama、vLLMの各エンドポイントが登録されている、**実行** タイプ「xLLM」でフィルタリングする、**結果** xLLMタイプのエンドポイントのみが返される
2. **前提** 複数のエンドポイントが登録されている、**実行** APIでタイプ指定なしでエンドポイント一覧を取得する、**結果** 全エンドポイントがタイプ情報付きで返される

---

### ユーザーストーリー8 - xLLMエンドポイントへのモデルダウンロード (優先度: P1)

運用者として、llmlbからxLLMエンドポイントに対してモデルダウンロードを指示したい。xLLMは本プロジェクト独自のエンジンであり、llmlbから一元管理したい。

**この優先度の理由**: xLLMの運用における中核機能であり、タイプ判別の主要なユースケース。

**独立テスト**: xLLMエンドポイントに対してモデルダウンロードを実行し、成功することを確認する。非xLLMエンドポイントに対しては拒否されることも確認する。

**受け入れシナリオ**:

1. **前提** xLLMタイプのエンドポイントが登録されている、**実行** llmlbからそのエンドポイントに対してモデルダウンロードを指示する、**結果** xLLMがモデルをダウンロード開始し、進捗が取得できる
2. **前提** Ollamaタイプのエンドポイントが登録されている、**実行** llmlbからそのエンドポイントに対してモデルダウンロードを指示する、**結果** 「このエンドポイントタイプではモデルダウンロードはサポートされていません」とエラーが返される
3. **前提** xLLMエンドポイントでモデルダウンロード中、**実行** 進捗を確認する、**結果** ダウンロード進捗（パーセント、速度等）が取得できる

---

### ユーザーストーリー9 - モデルメタデータの取得（最大トークン数等） (優先度: P1)

運用者として、xLLMやOllamaエンドポイントからモデルの最大トークン数（コンテキスト長）などのメタデータを取得したい。これにより、適切なモデル選択やリクエスト制限の判断ができる。

**この優先度の理由**: モデルの能力情報はルーティング判断やユーザーへの情報提供に重要。xLLM/Ollamaはこの情報を提供できるため、タイプ判別と組み合わせて活用する。

**独立テスト**: xLLM/Ollamaエンドポイントのモデルから最大トークン数を取得し、正しい値が返されることを確認する。

**受け入れシナリオ**:

1. **前提** xLLMエンドポイントにモデルがロードされている、**実行** そのモデルのメタデータを取得する、**結果** 最大トークン数（コンテキスト長）が取得できる
2. **前提** Ollamaエンドポイントにモデルがロードされている、**実行** そのモデルのメタデータを取得する、**結果** 最大トークン数（num_ctx）が取得できる
3. **前提** vLLMまたはOpenAI互換エンドポイントが登録されている、**実行** モデルメタデータを取得しようとする、**結果** 「このエンドポイントタイプではメタデータ取得はサポートされていません」または利用可能な範囲の情報が返される

---

### ユーザーストーリー10 - ダッシュボードでのタイプ表示 (優先度: P2)

運用者として、ダッシュボードで各エンドポイントのタイプを確認したい。これにより、システム構成を一目で把握できる。

**この優先度の理由**: 視覚的な確認は運用上有用だが、API経由でのフィルタリングが主要機能であるため、優先度をP2とする。

**独立テスト**: エンドポイント一覧画面でタイプ情報が表示されることを確認する。

**受け入れシナリオ**:

1. **前提** 複数タイプのエンドポイントが登録されている、**実行** ダッシュボードのエンドポイント一覧を表示する、**結果** 各エンドポイントにタイプ（xLLM/Ollama/vLLM/OpenAI互換）が表示される

---

### ユーザーストーリー11 - 手動タイプ指定のオーバーライド (優先度: P3)

運用者として、自動判別が正しくない場合やカスタム設定が必要な場合に、エンドポイントのタイプを手動で指定・変更したい。

**この優先度の理由**: 通常は自動判別で十分だが、エッジケースへの対応として必要。

**独立テスト**: エンドポイント登録時または編集時にタイプを手動指定し、その値が自動判別より優先されることを確認する。

---

### ユーザーストーリー12 - タイプ判定の説明責任 (優先度: P1)

運用者として、エンドポイントタイプが「なぜその判定になったのか」「いつ判定されたのか」「手動か自動か」を確認したい。これにより、誤判定や構成変更時に原因が追跡できる。

**この優先度の理由**: タイプ判定はxLLM固有機能や運用判断の前提であり、説明責任がないと運用トラブル時の復旧が困難になる。

**独立テスト**: 既存のタイプ判別・手動上書き・再判別のフローで、判定メタデータがAPIレスポンスとダッシュボードに表示されることを確認する。

**受け入れシナリオ**:

1. **前提** 自動判別でxLLMが検出される、**実行** エンドポイントを登録、**結果** `endpoint_type_source=auto`、`endpoint_type_reason` に判定根拠、`endpoint_type_detected_at` に時刻が入る
2. **前提** 手動でタイプを上書きする、**実行** エンドポイントのタイプを変更、**結果** `endpoint_type_source=manual`、`endpoint_type_reason` が手動理由（未指定時は既定文言）、`endpoint_type_detected_at` が更新される
3. **前提** Unknown状態のエンドポイントがオンラインになり再判別される、**実行** ヘルスチェックが成功、**結果** 判定タイプと同時に`endpoint_type_source=auto`/`endpoint_type_reason`/`endpoint_type_detected_at`が更新される

**受け入れシナリオ**:

1. **前提** エンドポイント登録画面を開いている、**実行** タイプを手動で「xLLM」と指定して登録する、**結果** 自動判別をスキップし、指定したタイプが保存される

---

### エッジケース

- 登録時にエンドポイントが一時的に応答しない場合、どのように扱うか？→ 登録は受け付け、状態を「保留中」として次回チェックを待つ
- ヘルスチェック中にエンドポイントがタイムアウトした場合、何が起こるか？→ エラー回数をカウントし、閾値超過でオフライン遷移
- モデル同期中にエンドポイントが応答しない場合、どうなるか？→ 同期失敗としてログに記録、既存のモデル情報は維持
- 初回ヘルスチェック失敗時、pending→offlineへの遷移は許可する（厳密なステータス管理）
- エンドポイント削除時、そのエンドポイントのみが提供していたモデルへのリクエストは404 Not Foundを返す
- GET /v1/modelsのレスポンス形式がOpenAI標準と異なる場合、複数形式（OpenAI/Ollama）をパースする
- エンドポイントがオフラインの場合、タイプは「不明」として保存され、次回オンライン時に再判別される
- 複数の判別条件に一致する場合、より具体的なタイプ（xLLM > Ollama > vLLM > OpenAI互換の順）を優先する
- 新しいタイプのサーバーが追加された場合、「OpenAI互換」としてフォールバックする
- xLLM以外のエンドポイントへのモデルダウンロード要求は明確なエラーメッセージで拒否する

## Clarifications

### Session 2026-01-14

**ルーティング戦略**:

- Q: 複数エンドポイントが同一モデルを提供している場合のルーティング戦略は？
- A: レイテンシベース（過去の応答時間が短いエンドポイントを優先）
- レイテンシはヘルスチェック時（30秒間隔）に更新

**APIキー暗号化**:

- Q: エンドポイントのAPIキー暗号化の鍵管理は？
- A: 既存JWTシークレットをベースに鍵を導出（AES-256-GCM）

**capabilities判定**:

- Q: モデルのcapabilities（chat/embeddings）はどう判定する？
- A: モデル名プレフィックスで自動判定（embed*→embeddings、それ以外→chat）

**モデル同期**:

- Q: エンドポイント登録時にモデル同期を自動実行する？
- A: 登録時に自動同期（UX向上）
- Q: エンドポイントから削除されたモデルの扱いは？
- A: 自動削除（ロードバランサーからも削除）

**オフライン時のモデル表示**:

- Q: エンドポイントがofflineになった際、モデル一覧での扱いは？
- A: 表示するがofflineマーク付き

**接続テストとヘルスチェック**:

- Q: 接続テストはステータスを更新する？
- A: 接続テストもステータスを更新（即時ヘルスチェックと同等）
- Q: 「即時チェック」ボタンは必要？
- A: 必要（ダッシュボードから任意のタイミングで手動チェック可能）

**タイムアウト設計**:

- Q: ヘルスチェックと推論リクエストのタイムアウトは別？
- A: 別設定（HC: 5秒固定、推論: リクエスト単位で設定可能）

**ダッシュボード表示**:

- Q: エンドポイント一覧の表示項目は？
- A: 基本情報（名前、URL、ステータス、モデル数）＋メトリクス（レイテンシ、エラー率、最終確認時刻）

**ステータス遷移**:

- Q: errorステータスからの復帰は？
- A: 次回ヘルスチェック成功で自動復帰（error→online）

**エラー履歴**:

- Q: ヘルスチェック履歴は保存する？
- A: 全履歴を別テーブルに保存、保存期間は30日間

**URL変更**:

- Q: エンドポイントURLの変更は許可する？
- A: 禁止（削除→再登録が必要）

**ロードバランサー再起動時**:

- Q: ヘルスチェッカーの再起動時動作は？
- A: 全エンドポイント即時チェック（並列実行）

**名前の一意性**:

- Q: エンドポイント名のUNIQUE制約は？
- A: 名前もUNIQUE必須（URLと名前の両方が一意）

**viewerロール**:

- Q: viewerロールのエンドポイント管理APIアクセス権限は？
- A: GETのみ許可（一覧・詳細の参照のみ）

**モデル指定**:

- Q: モデル指定時のエンドポイントプレフィックスは？
- A: プレフィックスなし（モデル名のみで指定、ロードバランサーが自動選択）

## 要件

### 機能要件

- **FR-001**: 管理者はダッシュボードからエンドポイントを登録できる必要がある
- **FR-002**: 管理者はREST APIからエンドポイントを登録できる必要がある
- **FR-003**: システムは登録済みエンドポイントの一覧を表示できる必要がある
- **FR-004**: システムはエンドポイントの稼働状況を定期的にチェックする必要がある（GET /v1/models）
- **FR-005**: システムはエンドポイントの状態（保留中、オンライン、オフライン、エラー）を管理する必要がある
- **FR-006**: システムはエンドポイントからモデル一覧を取得・同期できる必要がある（GET /v1/models）
- **FR-007**: 管理者は登録前にエンドポイントへの接続テストを実行できる必要がある
- **FR-008**: 管理者はエンドポイントを編集・削除できる必要がある
- **FR-009**: システムはエンドポイントのURLの重複を検出し、拒否する必要がある
- **FR-010**: システムはAPIキーが必要なエンドポイントの認証情報を安全に保存する必要がある
- **FR-011**: システムはエンドポイント名の重複を検出し、拒否する必要がある
- **FR-012**: システムはエンドポイント登録時に自動でモデル同期を実行する必要がある
- **FR-013**: システムはレイテンシベースのルーティングで複数エンドポイント間の負荷分散を行う必要がある
- **FR-014**: システムはヘルスチェック履歴を30日間保存する必要がある
- **FR-015**: viewerロールはエンドポイント管理APIの参照（GET）のみ可能である必要がある
- **FR-016**: 管理者はダッシュボードから即時ヘルスチェックを実行できる必要がある
- **FR-017**: システムはロードバランサー起動時に全エンドポイントの即時チェックを並列実行する必要がある
- **FR-018**: システムはモデルのcapabilitiesをモデル名プレフィックスから自動判定する必要がある

#### エンドポイントタイプ自動判別（追加要件 2026-01-26）

- **FR-019**: システムはエンドポイント登録時にサーバーへアクセスし、タイプを自動判別する必要がある
- **FR-020**: システムは判別したタイプをデータベースに永続化する必要がある
- **FR-021**: システムはxLLM、Ollama、vLLM、OpenAI互換の4タイプを判別できる必要がある
- **FR-022**: ユーザーはAPIを通じてタイプによるエンドポイントフィルタリングができる必要がある
- **FR-023**: ユーザーはダッシュボードでエンドポイントのタイプを確認できる必要がある
- **FR-024**: ユーザーは必要に応じてタイプを手動で指定・変更できる必要がある
- **FR-025**: システムはエンドポイントがオフラインの場合、タイプを「不明」として保存し、エラーにしない必要がある
- **FR-026**: システムはxLLMタイプのエンドポイントに対してのみ、モデルダウンロード機能を提供する必要がある
- **FR-027**: システムはxLLM以外のエンドポイントへのモデルダウンロード要求を明確なエラーで拒否する必要がある
- **FR-028**: システムはxLLMエンドポイントのモデルダウンロード進捗を取得できる必要がある
- **FR-029**: システムはxLLM/Ollamaエンドポイントからモデルの最大トークン数（コンテキスト長）を取得できる必要がある
- **FR-030**: システムはダッシュボードのステータス表示（一覧・詳細・Playground）で `pending` / `online` / `offline` / `error` を状態別に色分けして表示する必要がある

### 廃止される機能

以下の機能は本仕様により廃止される：

- **SPEC-94621a1f**: ノード自己登録システム（エンドポイント側からロードバランサーへの登録）
- **POST /api/nodes**: ノード登録エンドポイント
- **POST /api/health**: ノードからのハートビート受信エンドポイント
- **X-Node-Token**: ノードトークン認証

### 主要エンティティ

- **エンドポイント**: OpenAI互換APIの接続先。名前、URL、認証情報、状態、タイプを持つ
- **エンドポイント状態**: 保留中（未確認）、オンライン（稼働中）、オフライン（停止）、エラー（異常）
- **エンドポイントタイプ**: エンドポイントの種別（xLLM/Ollama/vLLM/OpenAI互換/不明）。判別ロジックと対応機能の紐付けに使用
- **エンドポイントモデル**: エンドポイントで利用可能なモデルの情報（GET /v1/modelsで取得）
- **モデルダウンロードタスク**: xLLMエンドポイントへのモデルダウンロード要求。進捗状況を追跡

---

## 関連仕様

- [SPEC-82cd11b7](../SPEC-82cd11b7/spec.md): API統合リファレンス — 全APIエンドポイントのカタログ・認証モデル分類・設計規約

## スコープ外

以下の機能は本仕様のスコープ外とし、将来のバージョンで対応予定:

- エンドポイントの自動発見（ネットワークスキャン等）
- エンドポイントグループ化・タグ付け機能
- エンドポイント間の負荷分散ポリシーのカスタマイズ
- 複数ロードバランサー間でのエンドポイント情報共有

---

## 技術制約

- 既存のクラウドプロバイダー連携（openai:、google:、anthropic:プレフィックス）は維持する
- ヘルスチェックはロードバランサー側からのプル型で実装する（ノードからのプッシュ型は廃止）

---

## 前提条件

この機能は以下を前提とします:

- ロードバランサーのダッシュボード（SPEC-712c20cf）が利用可能であること
- 管理者認証（JWT認証）が実装済みであること
- REST API認証（APIキー認証）が実装済みであること

---

## 依存関係

この機能は以下に依存します:

- SPEC-712c20cf: 管理ダッシュボード（UIの提供基盤）
- SPEC-63acef08: 統一APIプロキシ（エンドポイントへのリクエスト転送）
- SPEC-7c0a37e0: APIキースコープシステム（エンドポイント管理権限）

以下のSPECを廃止・置換します:

- SPEC-94621a1f: ノード自己登録システム（本仕様により完全に置換）
- SPEC-443acc8c: ヘルスチェックシステム（プル型に移行）

以下のSPECを更新します:

- SPEC-7c0a37e0: `endpoints`スコープ追加、`node`スコープ廃止

---

## 成功基準

以下の成功基準を満たす必要があります:

1. 管理者は1分以内にダッシュボードからエンドポイントを登録できる
2. 管理者は30秒以内にAPIからエンドポイントを登録できる
3. システムは60秒以内にエンドポイントの障害を検知し、オフライン状態に遷移する
4. システムはエンドポイント復旧後、次回ヘルスチェックでオンライン状態に復帰する
5. モデル同期実行後、エンドポイントの全モデルがロードバランサーに反映される
6. 既存のクラウドプロバイダー連携（openai:等）は引き続き正常に動作する
7. xLLM/Ollama/vLLMの各エンドポイントが正しいタイプとして判別される成功率が95%以上
8. エンドポイント登録時のタイプ判別が1秒以内に完了する
9. タイプによるフィルタリングAPIが正しい結果を返す
10. ダッシュボードで全エンドポイントのタイプが視覚的に確認できる
11. xLLMエンドポイントへのモデルダウンロードが正常に実行できる
12. 非xLLMエンドポイントへのモデルダウンロード要求が適切に拒否される
13. xLLM/Ollamaエンドポイントからモデルの最大トークン数が取得できる
14. ダッシュボードのステータス表示が `pending` / `online` / `offline` / `error` で一貫した色分けになる
